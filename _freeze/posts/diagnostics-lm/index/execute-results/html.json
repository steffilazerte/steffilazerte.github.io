{
  "hash": "88150f78c66d1b91c7a162fe3e5fd40c",
  "result": {
    "markdown": "---\ntitle: \"Diagnostics for Simple Linear Models\"\ndate: \"2022-11-15\"\ncategories: [stats, lm, vif, normality, diagnostics, residuals, cooks-d]\ntoc: true\ntoc-depth: 4\nexecute:\n  message: false\n  warning: false\nfig-width: 10\n---\n\n\n\nAll models have assumptions and cautions. Understanding whether you've satisfied\nthese assumptions and checking for potential problems are some of the hardest\nthings to do in statistics. \n\nFor simple linear models (`lm()`) the **main assumptions** are\n\n- **Linear relationship** between response (`y`) and predictors (`x`'s).\n- **Independence** - Observations are independent\n  - no hierarchical sampling, no nested designs, no variables are calculated from each other\n- **Normality** - Residuals are normally distributed\n- **Constant variance** - There is constant variance in residuals (no heteroscedasticity)\n\n> Note that it's the normality of **residuals** and NOT the raw data that matters\n\nAnd the **main cautions** are\n\n- **Multicollinearity** - You don't want high levels of multicollinearity\n  - When predictors are highly correlated they can to influence the parameters calculated\n- **Influence** - You don't want one or two points have an undue influence on your model\n  - Otherwise you should think about how relevant (and generalizable) that model really is\n\n\n### Diagnostics in R\n\nSome assumptions/cautions are those of design (i.e. Independence), and some are\nassessed by evaluating your model fit in R. Some, like the expectation of a\nLinear Relationship, can be assessed in different ways, by plotting your\nrelationship, or by looking at your residuals (as if there's a problem, you'll\nsee problems in the Normality and Variance of your residuals).\n\nIn R, we can extract the *residuals* (`residuals()`) and *fitted* (`fitted()`)\nvalues to assess Normality and Constant variance. We can also use functions like\n`vif()` and `cooks.distance()` to calculate metrics which will help us assess\nMulticollinearity and Influential observations.\n\nLet's extract and calculate the observation-level values we'll need for these \nassessments.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(palmerpenguins) # For penguins data set\nlibrary(dplyr)          # For data manipulation\n\n# We'll only use Adelie penguins for now\np <- filter(penguins, species == \"Adelie\") \n\n# Run model\nm <- lm(body_mass_g ~ bill_depth_mm, data = p, na.action = na.exclude)\n\n# Extract residuals and fitted values\np <- mutate(p, \n            resid = residuals(m),      # Residuals\n            fitted = fitted(m),        # Fitted values\n            cooks = cooks.distance(m), # Cook's distance\n            obs = 1:n())               # Observation ids\n```\n:::\n\n\n\n### Assessing Assumptions\nWe use **residuals** to look at this fit.\n\n#### What are residuals?\nFor a simple linear model, residuals are essentially the error between your\nobservations and your model. Fitted values are the predicted value of your \nresponse given the model and your explanatory values.\n\nFor example, in this linear model looking at the relationship between `body_mass_g`\nand `bill_depth_mm` in Adelie penguins, we can picture the residuals as the \ndegree of difference between the model line and our data points. \n\n\n\n::: {.cell fig.asp='0.4'}\n\n```{.r .cell-code  code-fold=\"true\"}\nlibrary(patchwork)      # To combine plots\nlibrary(ggplot2)        # For plotting\nlibrary(tidyr)          # For data manipulation\n\n# Model plot\ng1 <- ggplot(data = p, aes(x = bill_depth_mm, y = body_mass_g)) +\n  stat_smooth(method = \"lm\", se = FALSE, colour = \"black\") +\n  geom_point(size = 2)\n\n# Add residuals\ng2 <- g1 +\n  geom_segment(aes(xend = bill_depth_mm, yend = fitted, colour = resid), size = 1) +\n  scale_colour_viridis_c()\n\ng1 + g2\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-2-1.png){width=960}\n:::\n:::\n\n\n#### Normality\nWe want our residuals from our model to be normally distributed. We can use\na histogram or a QQ plot to assess this based on the residuals we extract from \nthe model.\n\n\n::: {.cell fig.asp='0.4'}\n\n```{.r .cell-code}\n# Histogram\ng1 <- ggplot(data = p, aes(x = resid)) +\n  geom_histogram()\n\n# QQ Plot\ng2 <- ggplot(data = p, aes(sample = resid)) +\n  stat_qq() +\n  stat_qq_line()\n\ng1 + g2\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-3-1.png){width=960}\n:::\n:::\n\n\n**Looks good!**\n\n#### Constant variance\nWe want the variability in our model residuals to be relatively constant\n(or at least to not show any definied patterns). It shouldn't\nincrease or decrease with the fitted values, and should be relatively scattered\nthroughout. We can plot the residuals by fitted values to make sure we don't\nsee any patterns.\n\nWe're checking for *heteroscedasticity*\n\n\n\n::: {.cell layout-align=\"center\" fig.asp='0.8'}\n\n```{.r .cell-code}\nggplot(data = p, aes(x = fitted, y = resid)) +\n  geom_point() +\n  geom_hline(yintercept = 0)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-4-1.png){fig-align='center' width=60%}\n:::\n:::\n\n\n**Looks good!**\n\n### Check for problems\n\n#### Multicollinearity\n\nMulticollinearity assess whether your *explanatory* variables are overly\ncorrelated. This means it only applies if you have a *multiple* regression\n(i.e.. where you have more than one explanatory variable).\n\nLet's consider this model\n\n::: {.cell}\n\n```{.r .cell-code}\nm2 <- lm(body_mass_g ~ bill_depth_mm + flipper_length_mm, data = p, na.action = na.exclude)\n```\n:::\n\n\n\nLook at our two explanatory variables\n\n::: {.cell fig.asp='0.7'}\n\n```{.r .cell-code}\nggplot(data = p, aes(x = flipper_length_mm, y = bill_length_mm)) +\n  geom_point() +\n  stat_smooth(method = \"lm\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-6-1.png){width=576}\n:::\n:::\n\n\nThey are definitely correlated, but that doesn't mean we have a problem.\nWe need to investigate if it interferes with the model.\n\nThere are several ways to assess multicollinearity. Here we'll use `vif()`^[VIF:\nvariance inflation factor; Can be interpreted as how much influence the\nvariable has on the model] function from `car` package.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(car)\nvif(m2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n    bill_depth_mm flipper_length_mm \n         1.104521          1.104521 \n```\n:::\n:::\n\n\nAlthough with all statistical measures, there is no magic number, generally \na VIF > 10 is considered a problem, and VIF > 5 is concerning.\n\nSo in this case we can assume that while there *is* a correlation, it's not\nhaveing an undue effect on how we interpret the model.\n\n\n\n\n\n#### Influence\nYou'll want to check if your model results are highly influenced by any specific\nobservations. For example, if you remove one observation and the entire model\nchanges, you'll have to think about how generalizable that model really is.\n\nOne way of checking whether any observations have an unusually high influence \non your model is to look at the Cook's distance (D). \n\nThere are several ways of considering what D is too high. One is that D below 1\nis good, the other is that you should aim for a D below 4 / no. observations.\n\n\n::: {.cell layout-align=\"center\" fig.asp='0.8'}\n\n```{.r .cell-code}\ng <- ggplot(p, aes(x = obs, y = cooks)) +\n  geom_point()\n\ng + geom_hline(yintercept = 1, linetype = \"dotted\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-8-1.png){fig-align='center' width=60%}\n:::\n\n```{.r .cell-code}\ng + geom_hline(yintercept = 4/nrow(p), \n                linetype = \"dashed\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-8-2.png){fig-align='center' width=60%}\n:::\n:::\n\n\n**All in all, having a high D doesn't mean you automatically remove the observation, \nit means you think about what influence that observation is having on your model.\nTry omitting it and see how your model changes!**\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}