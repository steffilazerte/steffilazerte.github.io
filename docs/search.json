[
  {
    "objectID": "tips_and_tricks.html",
    "href": "tips_and_tricks.html",
    "title": "Tips & Tricks",
    "section": "",
    "text": "This is a collection statistical notes, general tips and tricks, and useful citations which serve as a reference I can use when helping others with R, especially for statistics in the natural sciences.\nI sometimes include some statistical guidance, but generally speaking I assume some background in statistics. Generally, these notes cover more of the how, not the why of statistics.\nEverywhere possible I cite my information be it a stackoverflow question or an academic journal article. If you have a citation you think I should include or think thereâ€™s something Iâ€™m missing, please open an issue in the GitHub repository and let me know (ideally with a citation!)\n\nThis is a living collection and things might change!\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSpecial symbols in ggplot2\n\n\n\n\n\n\nggplot2\n\n\nvisualizations\n\n\nR\n\n\n\n\n\n\n\n\n\nMar 15, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nMapping Weather Data\n\n\n\n\n\n\nweathercan\n\n\nsf\n\n\nGIS\n\n\nleaflet\n\n\nR\n\n\n\n\n\n\n\n\n\nSep 20, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nUseful R Packages & Resources\n\n\n\n\n\n\npackages\n\n\nresources\n\n\nR\n\n\n\n\n\n\n\n\n\nSep 4, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nMaking a Website with GitHub/Quarto\n\n\n\n\n\n\ngithub\n\n\nwebsite\n\n\nprofiles\n\n\nR\n\n\n\n\n\n\n\n\n\nAug 23, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nInterpreting Interactions\n\n\n\n\n\n\nstats\n\n\nmodels\n\n\ninteractions\n\n\npredictions\n\n\nR\n\n\n\n\n\n\n\n\n\nJun 6, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nDHARMa - Diagnostics for General Linear Models\n\n\n\n\n\n\nstats\n\n\nlm\n\n\ndiagnostics\n\n\nglm\n\n\nR\n\n\n\n\n\n\n\n\n\nDec 1, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nDiagnostics for Simple Linear Models\n\n\n\n\n\n\nstats\n\n\nlm\n\n\nvif\n\n\nnormality\n\n\ndiagnostics\n\n\nresiduals\n\n\ncooks-d\n\n\nR\n\n\n\n\n\n\n\n\n\nNov 15, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nRunning Basic Linear Models\n\n\n\n\n\n\nstats\n\n\nlm\n\n\nR\n\n\n\n\n\n\n\n\n\nNov 13, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nStatistical Workflow\n\n\n\n\n\n\nstats\n\n\nlm\n\n\n\n\n\n\n\n\n\nNov 10, 2022\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "presentations.html",
    "href": "presentations.html",
    "title": "Presentations",
    "section": "",
    "text": "Organized and invited speakers for this lightning symposium at the 2021-08 Joint meeting of the American Ornithological Society and Society of Canadian Ornithologists / SociÃ©tÃ© des ornithologistes du Canada\n\n\nSymposium details\n\n\n\nSteffi LaZerte - â€œHow can ornithologists find R packages?â€ (GitHub | html | pdf | video)\nStepfanie Aguillon - â€œdplyr: A useful toolbox for manipulating dataâ€ (GitHub)\nMatt Dyson - â€œsf, raster, and tmap: The spatial data trinityâ€ (GitHub)\nMark Padgham - â€œosmdata: Roadless areas and avian diversityâ€ (GitHub | video)\nSunny Tseng - â€œseewave and tuneR: Sound analysis in ornithologyâ€\nMarÃ­a Juliana BenÃ­tez SaldÃ­var - â€œwarbler and Rraven: Bioacoustics in Râ€\nJohn Quinn - â€œsoundecology: Using acoustic indices for landscape assessment and monitoringâ€\nDanielle Ethier - â€œnaturecounts: Millions of bird occurrence records at your fingertipsâ€ (pdf)\nJessica Burnett - â€œbbsAssistant: An R package for downloading and handling data and information from the North American Breeding Bird Surveyâ€ (Contact for details)\nAmie MacDonald - â€œmotus: Managing motus data in Râ€\nMartin Beal - â€œtrack2KBA: An R package for identifying important sites for biodiversity from tracking dataâ€\nElena West - â€œMixSIAR: An R package for avian diet analysisâ€ (pdf)\nEvan Adams - â€œINLA: A way for ecologists to overcome their worst impulsesâ€\nLuke Campillo - â€œpavo: Color analysis in birdsâ€\nPhilipp Boersch-Supan - â€œmoult and moultmcmc: Inference for moult phenology modelsâ€ (pdf | transcript)\nMarc-Olivier Beausoleil - â€œPutting it all together: Ornithometrics â€” a task view for ornithologyâ€\n\n\n\n\n\nOrganized and invited speakers for this symposium at the 2019-08 Society of Canadian Ornithologists / SociÃ©tÃ© des ornithologistes du Canada\n\n\nSymposium details\n\n\n\nSteffi LaZerte - â€œR for Ornithologists: How R can benefit the study of Ornithologyâ€ (GitHub | html EN | pdf EN | html FR | pdf FR\nKen A. Otter, Steffi LaZerte & Isobel Hartley - â€œThe blessing and curse of automated data collection: R and dealing with big data in a modern ageâ€\nDenis LePage, Steffi LaZerte & Danielle Ethier - â€œnaturecounts: a new R package to access standardized data on bird populationsâ€ (pdf FR)\nAdam C. Smith & Brandon P.M. Edwards - â€œSuper-computing with R: Harnessing the power of the cloud to analyze big-bird-data, or just run your simulations, models, and cross-validations fasterâ€\nBrandon P.M. Edwards, Adam C. Smith, Marie-Anne R. Hudson, Charles M. Francis, Keith L. Pardieck, David J. Ziolkowski Jr.Â - â€œbbsBayes: An R package for hierarchical Bayesian modelling of Breeding Bird Survey dataâ€\nEliza M. Grames, Andrew N. Stillman, Carolyn V. Mills, Morgan W. Tingley, Chris S. Elphick - â€œConducting partially automated systematic reviews with the litsearchr package in Râ€ (pdf EN/FR)\nDarren S. Proppe - â€œUsing R in the undergraduate biology classroom: Hurdles, hints, and aha momentsâ€"
  },
  {
    "objectID": "presentations.html#organized-symposia",
    "href": "presentations.html#organized-symposia",
    "title": "Presentations",
    "section": "",
    "text": "Organized and invited speakers for this lightning symposium at the 2021-08 Joint meeting of the American Ornithological Society and Society of Canadian Ornithologists / SociÃ©tÃ© des ornithologistes du Canada\n\n\nSymposium details\n\n\n\nSteffi LaZerte - â€œHow can ornithologists find R packages?â€ (GitHub | html | pdf | video)\nStepfanie Aguillon - â€œdplyr: A useful toolbox for manipulating dataâ€ (GitHub)\nMatt Dyson - â€œsf, raster, and tmap: The spatial data trinityâ€ (GitHub)\nMark Padgham - â€œosmdata: Roadless areas and avian diversityâ€ (GitHub | video)\nSunny Tseng - â€œseewave and tuneR: Sound analysis in ornithologyâ€\nMarÃ­a Juliana BenÃ­tez SaldÃ­var - â€œwarbler and Rraven: Bioacoustics in Râ€\nJohn Quinn - â€œsoundecology: Using acoustic indices for landscape assessment and monitoringâ€\nDanielle Ethier - â€œnaturecounts: Millions of bird occurrence records at your fingertipsâ€ (pdf)\nJessica Burnett - â€œbbsAssistant: An R package for downloading and handling data and information from the North American Breeding Bird Surveyâ€ (Contact for details)\nAmie MacDonald - â€œmotus: Managing motus data in Râ€\nMartin Beal - â€œtrack2KBA: An R package for identifying important sites for biodiversity from tracking dataâ€\nElena West - â€œMixSIAR: An R package for avian diet analysisâ€ (pdf)\nEvan Adams - â€œINLA: A way for ecologists to overcome their worst impulsesâ€\nLuke Campillo - â€œpavo: Color analysis in birdsâ€\nPhilipp Boersch-Supan - â€œmoult and moultmcmc: Inference for moult phenology modelsâ€ (pdf | transcript)\nMarc-Olivier Beausoleil - â€œPutting it all together: Ornithometrics â€” a task view for ornithologyâ€\n\n\n\n\n\nOrganized and invited speakers for this symposium at the 2019-08 Society of Canadian Ornithologists / SociÃ©tÃ© des ornithologistes du Canada\n\n\nSymposium details\n\n\n\nSteffi LaZerte - â€œR for Ornithologists: How R can benefit the study of Ornithologyâ€ (GitHub | html EN | pdf EN | html FR | pdf FR\nKen A. Otter, Steffi LaZerte & Isobel Hartley - â€œThe blessing and curse of automated data collection: R and dealing with big data in a modern ageâ€\nDenis LePage, Steffi LaZerte & Danielle Ethier - â€œnaturecounts: a new R package to access standardized data on bird populationsâ€ (pdf FR)\nAdam C. Smith & Brandon P.M. Edwards - â€œSuper-computing with R: Harnessing the power of the cloud to analyze big-bird-data, or just run your simulations, models, and cross-validations fasterâ€\nBrandon P.M. Edwards, Adam C. Smith, Marie-Anne R. Hudson, Charles M. Francis, Keith L. Pardieck, David J. Ziolkowski Jr.Â - â€œbbsBayes: An R package for hierarchical Bayesian modelling of Breeding Bird Survey dataâ€\nEliza M. Grames, Andrew N. Stillman, Carolyn V. Mills, Morgan W. Tingley, Chris S. Elphick - â€œConducting partially automated systematic reviews with the litsearchr package in Râ€ (pdf EN/FR)\nDarren S. Proppe - â€œUsing R in the undergraduate biology classroom: Hurdles, hints, and aha momentsâ€"
  },
  {
    "objectID": "presentations.html#other",
    "href": "presentations.html#other",
    "title": "Presentations",
    "section": "Other",
    "text": "Other\n2022-04 - rOpenSci (GitHub)\n\n2022-04_rOpenSci (Rmd | html)\n\n2021-11 UofM - rOpenSci (GitHub)\n\n2021-11_UofM_rOpenSci (Rmd | html)\n\n2021-10 Edmonton R user group - rOpenSci (GitHub)\n\nEdmonton_R_user_rOpenSci (Rmd | html)\n\n2021-08 AOS|SOC - R Symposium (GitHub)\n\nAOS_SCO_2021_LaZerte (Rmd | html | video | pdf)\nElenaWest_LightningTalk_MixSIAR (pdf)\nnaturecounts_AOS_SCO Aug 2021 Final ENG-FR (pdf)\nsupplemental (Rmd | pdf)\n\n2021-08 ESA rOpenSci (GitHub)\n\n2021-08_ESA_rOpenSci (Rmd | html | pdf)\n2021-08_ESA_rOpenSci_handout (Rmd | pdf)\n\n2021-04 rOpenSci - Community (GitHub)\n\n2021-04_rOpenSci_community (Rmd | html)\n\n2019-11 rOpenSci - Testing (GitHub)\n\n2019-11_ROpenSci_Testing (Rmd | html | pdf)\n\n2019-08 SOC - R Symposium (GitHub)\n\nGrames_SCO-SOC_slides (pdf)\nLaZerte_SCO_SOC_2019_en (Rmd | html | pdf)\nLaZerte_SCO_SOC_2019_fr (Rmd | html | pdf)\nSCO_2019_naturecounts_R_Ethier_Final (pdf)\n\n2019-05 CRSC - naturecounts (GitHub)\n\nLaZerte_CRSC_naturecounts_2019 (Rmd | html | pdf)\n\n2018-08 ISBE (GitHub)\n\nLaZerte_ISBE_2018_cavityuse (Rmd | html | pdf)\n\n2018-07 Ag Canada - weathercan (GitHub)\n\nLaZerte_AGCAN_2018_weathercan (Rmd | html | pdf)\n\n2017-09 PCAG - weathercan (GitHub)\n\nLaZerte_PCAG_2017_weathercan (Rmd | html | pdf)\nLaZerte_PCAG_2017_weathercan_extra (Rmd | html | pdf)"
  },
  {
    "objectID": "posts/weathercan-mapping/index.html",
    "href": "posts/weathercan-mapping/index.html",
    "title": "Mapping Weather Data",
    "section": "",
    "text": "[2023-09-20] Until recently, this article was part of the documentation for the weathercan package. To simplify the docs while retaining this article, Iâ€™ve decided to move it here.\nThis example is a bit dated (it isnâ€™t the most modern approach), and is lacking in detailed explanations. However, I hope this is still useful as a more advanced example of how data can be combined using different types of tools.\nThis article is based on the blog post Integrating data from weathercan written for rOpenSci March 6th 2018.\nIn that article I demonstrated how we can incorporate data from weathercan into spatial visualizations. In this article Iâ€™d like to take that even further and show you how you can create interactive maps which highlight spatial variability in weather data.\nHere, weâ€™ll take a look at annual temperatures throughout different Eco Regions in Manitoba, Canada."
  },
  {
    "objectID": "posts/weathercan-mapping/index.html#setup",
    "href": "posts/weathercan-mapping/index.html#setup",
    "title": "Mapping Weather Data",
    "section": "Setup",
    "text": "Setup\nUsing extra CSS styles\nThe map that we create here may look different for you unless you include the tweaks to the CSS styles I have made. If youâ€™re using RMarkdown, you can supply these as a custom .css file, or inline with the &lt;style&gt; and &lt;/style&gt; tags (like below).\n&lt;style&gt;\ndiv.leaflet-popup-content-wrapper {\n  width: 700px;\n  height: 100%;\n}\n\ndiv.leaflet-popup-tip-container {\n  opacity: 0;\n}\n\ndiv.leaflet-popup-content {\n  width: 90% !important;\n}\n\nimg {\n  max-width: 90% !important;\n  min-width: 90% !important;\n  border: none;\n}\n\n/* Fix the NA mis-alignment in the legend */\ndiv.info.legend.leaflet-control br {\n  clear: both;\n}\n&lt;/style&gt;\nLoading packages\n\nlibrary(dplyr)\nlibrary(purrr)\nlibrary(stringr)\nlibrary(ggplot2)\nlibrary(tidyr)\nlibrary(weathercan)\nlibrary(leaflet)\nlibrary(sf)\nlibrary(htmltools)\n\nDownload Manitoban Eco Regions shapefile\n\ndownload.file(\"http://mli2.gov.mb.ca/environment/shp_zip_files/env_ecological_areas_py_shp.zip\",\n              destfile = \"ecological_shp.zip\")\nunzip(\"ecological_shp.zip\")\nfile.remove(\"ecological_shp.zip\")\n\n[1] TRUE\n\n\nDownload Manitoba weather data\nWeâ€™ll select all currently operating stations (end &gt;= 2018) and download the daily weather data for 2017:\n\nmb &lt;- filter(stations(), prov == \"MB\", interval == \"day\", end &gt;= 2018)\nw &lt;- weather_dl(mb$station_id, start = \"2017-01-01\", end = \"2017-12-31\", interval = \"day\")"
  },
  {
    "objectID": "posts/weathercan-mapping/index.html#calculating-summaries",
    "href": "posts/weathercan-mapping/index.html#calculating-summaries",
    "title": "Mapping Weather Data",
    "section": "Calculating summaries",
    "text": "Calculating summaries\nIn this section, weâ€™ll summarize our data and create the means of showcasing it in our map. Weâ€™ll calculate some basic summaries and weâ€™ll style some popups to contain this information (including the figures weâ€™ll create later).\nWeâ€™ll do a station-specific summaries/pop-ups for when users click on a station marker, and region-specific ones for when they click on the region polygon.\nStation summaries\n\nmb_stations &lt;- w %&gt;%\n  group_by(station_id) %&gt;%\n  mutate(n = n(),\n         n_missing = sum(is.na(mean_temp)),\n         mean_temp = mean(mean_temp, na.rm = TRUE)) %&gt;%\n  filter((n - n_missing) &gt; 0) %&gt;% # Only keep stations with some temperature data\n  select(station_name, station_id, lat, lon, mean_temp, n, n_missing) %&gt;%\n  distinct() %&gt;%\n  mutate(station_name = tools::toTitleCase(tolower(station_name)),\n         info = paste0(\"&lt;h3&gt;Station: \", station_name, \" (\", station_id, \")&lt;/h2&gt;\",\n                       \"&lt;hr&gt;\",\n                       \"&lt;div&gt;\",\n                       \"&lt;strong&gt;Mean Temperature: &lt;/strong&gt;\", round(mean_temp, 1), \"C&lt;br&gt;\",\n                       \"&lt;strong&gt;No. days with data:  &lt;/strong&gt;\", n-n_missing, \"&lt;br&gt;\",\n                       \"&lt;strong&gt;No. days total:  &lt;/strong&gt;\", n, \"&lt;/div&gt;\",\n                       \"&lt;img src = 'svg/\", station_id, \".svg'&gt;\"),\n         pretty_name = map(station_name, \n                           ~HTML(paste0(\"&lt;strong&gt;Station: &lt;/strong&gt;\", .x)))) %&gt;%\n  ungroup() %&gt;%\n  st_as_sf(coords = c(\"lon\", \"lat\"), crs = \"+proj=longlat\")\n\nEco Region summaries\nBefore we summarize this data, weâ€™ll filter the Eco Regions to just Manitoba and will join this to the stations data (after transforming the stations data to the same CRS), so we can figure out which stations belong to which regions.\n\nmb_ecoregions &lt;- st_read(\"env_ecological_areas.shp\") %&gt;%\n  filter(MANITOBA == \"yes\") %&gt;%\n  # Get the larger-scale regions and combine\n  group_by(ECOREGION, REGION_NAM, REGION_NOM) %&gt;%\n  summarize()\n\nReading layer `env_ecological_areas' from data source \n  `/home/steffi/Projects/AA Websites/steffilazerte.github.io/posts/weathercan-mapping/env_ecological_areas.shp' \n  using driver `ESRI Shapefile'\nSimple feature collection with 279 features and 15 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: -621621.3 ymin: 5386414 xmax: 1868189 ymax: 7166472\nProjected CRS: NAD83 / UTM zone 14N\n\n\n`summarise()` has grouped output by 'ECOREGION', 'REGION_NAM'. You can override\nusing the `.groups` argument.\n\nmb_stations &lt;- st_transform(mb_stations, crs = st_crs(mb_ecoregions))\n  \nmb_ecoregions &lt;- st_join(mb_ecoregions, mb_stations) %&gt;%\n  group_by(ECOREGION, REGION_NAM, REGION_NOM) %&gt;%\n  summarize(n_stations = length(unique(station_id[!is.na(station_id)])),\n            mean_temp = mean(mean_temp, na.rm = TRUE),\n            mean_temp = replace(mean_temp, is.nan(mean_temp), NA), \n            .groups = \"drop\") %&gt;%\n  mutate(info = paste0(\"&lt;h3&gt;Region: \", REGION_NAM, \"/\", REGION_NOM, \" (\", ECOREGION, \")&lt;/h2&gt;\",\n                       \"&lt;hr&gt;\",\n                       \"&lt;div&gt;\",\n                       \"&lt;strong&gt;Mean Temperature: &lt;/strong&gt;\", round(mean_temp, 1), \n                       if_else(!is.na(mean_temp), \"C&lt;br&gt;\", \"&lt;br&gt;\"),\n                       \"&lt;strong&gt;No. stations:  &lt;/strong&gt;\", n_stations, \"&lt;/div&gt;\"),\n         info = if_else(n_stations &gt; 0, \n                        paste0(info, \"&lt;img src = 'svg/\", ECOREGION, \".svg'&gt;\"),\n                        info),\n         pretty_name = map(REGION_NAM, \n                           ~HTML(paste0(\"&lt;strong&gt;Region: &lt;/strong&gt;\", .x)))) %&gt;%\n  ungroup()\n\nFigures\nWeâ€™ll set up some functions to create and save figures for our map\n\nplot_station_fig &lt;- function(d, station_id) {\n  g &lt;- ggplot(d, aes(x = date, y = mean_temp)) +\n    theme_bw() +\n    geom_line(na.rm = TRUE) +\n    labs(x = \"Date\", y = \"Mean Daily Temperature (C)\")\n  ggsave(paste0(\"svg/\", station_id, \".svg\"), plot = g,\n         width = 6, height = 3, dpi = 100)\n}\n\nplot_region_fig &lt;- function(d, region) {\n  g &lt;- ggplot(d, aes(x = date, y = mean_temp, \n                group = station_name, colour = station_name)) +\n    theme_bw() +\n    geom_line(na.rm = TRUE) +\n    scale_colour_viridis_d(end = 0.8) +\n    labs(x = \"Date\", y = \"Mean Daily Temperature (C)\", colour = \"Stations\")\n  ggsave(paste0(\"svg/\", region, \".svg\"), plot = g,\n         width = 6, height = 3, dpi = 100)\n}\n\nNow weâ€™ll apply these functions to our data. Note that this figs object isnâ€™t important, itâ€™s just used as a way to loop through the data and save the figures as svg files.\n\ndir.create(\"svg\")\n\nWarning in dir.create(\"svg\"): 'svg' already exists\n\nfigs &lt;- st_join(mb_stations, mb_ecoregions) %&gt;%\n  st_drop_geometry %&gt;%\n  left_join(select(w, station_id, date, mean_temp), by = \"station_id\") %&gt;%\n  nest(data = -ECOREGION) %&gt;%\n  mutate(fig_region = map2(data, ECOREGION, ~plot_region_fig(.x, .y))) %&gt;%\n  unnest(data) %&gt;%\n  nest(data = c(-ECOREGION, -station_id)) %&gt;%\n  mutate(fig_station = map2(data, station_id, ~plot_station_fig(.x, .y)))"
  },
  {
    "objectID": "posts/weathercan-mapping/index.html#mapping",
    "href": "posts/weathercan-mapping/index.html#mapping",
    "title": "Mapping Weather Data",
    "section": "Mapping",
    "text": "Mapping\nFinally, weâ€™re ready to create our map!\nWeâ€™ll start by transforming our data into WGS84 for leaflet, then weâ€™ll create a palette and get some iconsâ€¦\n\n# Required for Leaflet\nmb_ecoregions &lt;- st_transform(mb_ecoregions, crs = 4326)\nmb_stations &lt;- st_transform(mb_stations, crs = 4326)\n\n# Setup Palette for polygons\npal_eco &lt;- colorNumeric(palette = \"viridis\",\n                          domain = mb_ecoregions$mean_temp)\n\n# Get icons for stations (red if above average, blue if below)\nstation_icons &lt;- awesomeIcons(iconColor = \"black\", library = \"ion\",\n                              markerColor = ifelse(mb_stations$mean_temp &gt; \n                                                     mean(mb_stations$mean_temp, \n                                                          na.rm = TRUE), \n                                                   \"red\", \"blue\"))\n\nNow for the real magic!\n\nleaflet(width = \"750px\", height = \"85vh\") %&gt;% \n  addTiles() %&gt;%\n  addPolygons(data = mb_ecoregions,\n              color = \"#444444\", weight = 1, opacity = 1, fillOpacity = 0.5,\n              fillColor = ~pal_eco(mean_temp),\n              label = ~pretty_name, popup = ~info,\n              popupOptions = popupOptions(keepInView = TRUE),\n              highlightOptions = highlightOptions(bringToFront = TRUE, \n                                                  fillOpacity = 1)) %&gt;%\n  addAwesomeMarkers(data = mb_stations, group = \"Stations\",\n                    icon = station_icons,\n                    label = ~pretty_name, popup = ~info,\n                    popupOptions = popupOptions(keepInView = TRUE)) %&gt;%\n  addLegend(\"bottomright\", pal = pal_eco,\n            values = mb_ecoregions$mean_temp,\n            title = \"Mean region temperature\",\n            labFormat = labelFormat(suffix = \" C\")) %&gt;%\n  addLegend(\"bottomright\", \n            title = \"Station temperature\", \n            colors = c(\"#d63e2a\", \"#37a7da\"), opacity = 1, \n            labels = c(\"Above the average\", \"Below the average\")) %&gt;%\n  addLayersControl(\n    overlayGroups = \"Stations\",\n    options = layersControlOptions(collapsed = FALSE))\n\n\n\n\n\nI think this is an interesting way of looking at the Eco Regions in Manitoba.\nFirst we see a clear (and expected) pattern of decreasing temperatures with latitude (South to North). Further, we also see a bit of a South West to North East pattern.\nLooking at the Eco Regions like this gives a clear idea of some of the parameters that make these Eco Regions distinct. For example, the patch of lands in the lower left corner of the province are the Mid-Boreal Uplands and the Boreal Transition. See how much cooler they are (on average) than the rest of southern Manitoba.\nThese southern Boreal regions represent a distinct ecology in southern Manitoba. If you zoom in on the map, youâ€™ll see that they also hold two parks: Duck Mountain Provincial Park and Riding Mountain National Park.\nSession Info\n\ndevtools::session_info()\n\nâ”€ Session info â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n setting  value\n version  R version 4.3.3 (2024-02-29)\n os       Ubuntu 22.04.4 LTS\n system   x86_64, linux-gnu\n ui       X11\n language en_CA:en\n collate  en_CA.UTF-8\n ctype    en_CA.UTF-8\n tz       America/Winnipeg\n date     2024-03-15\n pandoc   3.1.1 @ /usr/lib/rstudio/resources/app/bin/quarto/bin/tools/ (via rmarkdown)\n\nâ”€ Packages â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n package      * version    date (UTC) lib source\n bit            4.0.5      2022-11-15 [1] CRAN (R 4.3.0)\n bit64          4.0.5      2020-08-30 [1] CRAN (R 4.3.0)\n cachem         1.0.8      2023-05-01 [1] CRAN (R 4.3.0)\n class          7.3-22     2023-05-03 [4] CRAN (R 4.3.1)\n classInt       0.4-10     2023-09-05 [1] CRAN (R 4.3.1)\n cli            3.6.2      2023-12-11 [1] CRAN (R 4.3.2)\n codetools      0.2-19     2023-02-01 [4] CRAN (R 4.2.2)\n colorspace     2.1-0      2023-01-23 [1] CRAN (R 4.3.0)\n crayon         1.5.2      2022-09-29 [1] CRAN (R 4.3.0)\n crosstalk      1.2.1      2023-11-23 [1] CRAN (R 4.3.2)\n curl           5.2.1      2024-03-01 [1] CRAN (R 4.3.2)\n DBI            1.2.2      2024-02-16 [1] CRAN (R 4.3.2)\n devtools       2.4.5      2022-10-11 [1] CRAN (R 4.3.0)\n digest         0.6.34     2024-01-11 [1] CRAN (R 4.3.2)\n dplyr        * 1.1.4      2023-11-17 [1] CRAN (R 4.3.2)\n e1071          1.7-14     2023-12-06 [1] CRAN (R 4.3.2)\n ellipsis       0.3.2      2021-04-29 [1] CRAN (R 4.3.0)\n evaluate       0.23       2023-11-01 [1] CRAN (R 4.3.1)\n fansi          1.0.6      2023-12-08 [1] CRAN (R 4.3.2)\n farver         2.1.1      2022-07-06 [1] CRAN (R 4.3.0)\n fastmap        1.1.1      2023-02-24 [1] CRAN (R 4.3.0)\n fs             1.6.3      2023-07-20 [1] CRAN (R 4.3.1)\n generics       0.1.3      2022-07-05 [1] CRAN (R 4.3.0)\n ggplot2      * 3.5.0      2024-02-23 [1] CRAN (R 4.3.2)\n glue           1.7.0      2024-01-09 [1] CRAN (R 4.3.2)\n gridExtra      2.3        2017-09-09 [1] CRAN (R 4.3.0)\n gtable         0.3.4      2023-08-21 [1] CRAN (R 4.3.1)\n hms            1.1.3      2023-03-21 [1] CRAN (R 4.3.0)\n htmltools    * 0.5.7      2023-11-03 [1] CRAN (R 4.3.1)\n htmlwidgets    1.6.4      2023-12-06 [1] CRAN (R 4.3.2)\n httpuv         1.6.14     2024-01-26 [1] CRAN (R 4.3.2)\n httr           1.4.7      2023-08-15 [1] CRAN (R 4.3.1)\n jquerylib      0.1.4      2021-04-26 [1] CRAN (R 4.3.0)\n jsonlite       1.8.8      2023-12-04 [1] CRAN (R 4.3.2)\n KernSmooth     2.23-22    2023-07-10 [1] CRAN (R 4.3.1)\n knitr          1.45       2023-10-30 [1] CRAN (R 4.3.1)\n labeling       0.4.3      2023-08-29 [1] CRAN (R 4.3.1)\n later          1.3.2      2023-12-06 [1] CRAN (R 4.3.2)\n leaflet      * 2.2.1      2023-11-13 [1] CRAN (R 4.3.2)\n lifecycle      1.0.4      2023-11-07 [1] CRAN (R 4.3.2)\n lubridate      1.9.3      2023-09-27 [1] CRAN (R 4.3.1)\n lutz           0.3.2      2023-10-17 [1] CRAN (R 4.3.1)\n magrittr       2.0.3      2022-03-30 [1] CRAN (R 4.3.0)\n memoise        2.0.1      2021-11-26 [1] CRAN (R 4.3.0)\n mime           0.12       2021-09-28 [1] CRAN (R 4.3.0)\n miniUI         0.1.1.1    2018-05-18 [1] CRAN (R 4.3.0)\n munsell        0.5.0      2018-06-12 [1] CRAN (R 4.3.0)\n pillar         1.9.0      2023-03-22 [1] CRAN (R 4.3.0)\n pkgbuild       1.4.3      2023-12-10 [1] CRAN (R 4.3.2)\n pkgconfig      2.0.3      2019-09-22 [1] CRAN (R 4.3.0)\n pkgload        1.3.3      2023-09-22 [1] CRAN (R 4.3.1)\n profvis        0.3.8      2023-05-02 [1] CRAN (R 4.3.1)\n promises       1.2.1      2023-08-10 [1] CRAN (R 4.3.1)\n proxy          0.4-27     2022-06-09 [1] CRAN (R 4.3.0)\n purrr        * 1.0.2      2023-08-10 [1] CRAN (R 4.3.1)\n R6             2.5.1      2021-08-19 [1] CRAN (R 4.3.0)\n ragg           1.2.6      2023-10-10 [1] CRAN (R 4.3.1)\n rappdirs       0.3.3      2021-01-31 [1] CRAN (R 4.3.0)\n RColorBrewer   1.1-3      2022-04-03 [1] CRAN (R 4.3.0)\n Rcpp           1.0.12     2024-01-09 [1] CRAN (R 4.3.2)\n readr          2.1.5      2024-01-10 [1] CRAN (R 4.3.2)\n remotes        2.4.2.1    2023-07-18 [1] CRAN (R 4.3.2)\n rlang          1.1.3      2024-01-10 [1] CRAN (R 4.3.2)\n rmarkdown      2.25       2023-09-18 [1] CRAN (R 4.3.1)\n rstudioapi     0.15.0     2023-07-07 [1] CRAN (R 4.3.1)\n s2             1.1.6      2023-12-19 [1] CRAN (R 4.3.2)\n scales         1.3.0      2023-11-28 [1] CRAN (R 4.3.2)\n sessioninfo    1.2.2      2021-12-06 [1] CRAN (R 4.3.0)\n sf           * 1.0-15     2023-12-18 [1] CRAN (R 4.3.2)\n shiny          1.8.0      2023-11-17 [1] CRAN (R 4.3.2)\n stringi        1.8.3      2023-12-11 [1] CRAN (R 4.3.2)\n stringr      * 1.5.1      2023-11-14 [1] CRAN (R 4.3.2)\n svglite        2.1.3      2023-12-08 [1] CRAN (R 4.3.2)\n systemfonts    1.0.5      2023-10-09 [1] CRAN (R 4.3.1)\n textshaping    0.3.7      2023-10-09 [1] CRAN (R 4.3.1)\n tibble         3.2.1      2023-03-20 [1] CRAN (R 4.3.0)\n tidyr        * 1.3.1      2024-01-24 [1] CRAN (R 4.3.2)\n tidyselect     1.2.0      2022-10-10 [1] CRAN (R 4.3.0)\n timechange     0.3.0      2024-01-18 [1] CRAN (R 4.3.2)\n tzdb           0.4.0      2023-05-12 [1] CRAN (R 4.3.1)\n units          0.8-5      2023-11-28 [1] CRAN (R 4.3.2)\n urlchecker     1.0.1      2021-11-30 [1] CRAN (R 4.3.0)\n usethis        2.2.2      2023-07-06 [1] CRAN (R 4.3.1)\n utf8           1.2.4      2023-10-22 [1] CRAN (R 4.3.1)\n vctrs          0.6.5      2023-12-01 [1] CRAN (R 4.3.2)\n viridis        0.6.5      2024-01-29 [1] CRAN (R 4.3.2)\n viridisLite    0.4.2      2023-05-02 [1] CRAN (R 4.3.1)\n vroom          1.6.5      2023-12-05 [1] CRAN (R 4.3.2)\n weathercan   * 0.7.0.9000 2023-09-20 [1] local\n withr          3.0.0      2024-01-16 [1] CRAN (R 4.3.2)\n wk             0.9.1      2023-11-29 [1] CRAN (R 4.3.2)\n xfun           0.42       2024-02-08 [1] CRAN (R 4.3.2)\n xtable         1.8-4      2019-04-21 [1] CRAN (R 4.3.0)\n yaml           2.3.8      2023-12-11 [1] CRAN (R 4.3.2)\n\n [1] /home/steffi/R/x86_64-pc-linux-gnu-library/4.3\n [2] /usr/local/lib/R/site-library\n [3] /usr/lib/R/site-library\n [4] /usr/lib/R/library\n\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€"
  },
  {
    "objectID": "posts/interactions/index.html",
    "href": "posts/interactions/index.html",
    "title": "Interpreting Interactions",
    "section": "",
    "text": "Creating models and checking their assumptions are the first steps to running an analysis, but once you have a beautiful, valid model, what next?\nInterpreting models can be tricky as some results arenâ€™t intuitive (i.e.Â often interactions, or non-Gaussian models), and to get the most out of your model, youâ€™ll want to understand both what parameters are important (or significant), as well as how they are important (effects size and direction).\nYou may also want to run a post-hoc analysis to dive deeper into the effects of categorical predictors.\nHere weâ€™ll take a quick look at interactions.\n\nlibrary(palmerpenguins)  # penguins data\nlibrary(car)             # Type 3 anova\nlibrary(marginaleffects) # Exploring interactions\nlibrary(ggplot2)\n\nInterpreting Interactions\nLetâ€™s see if there is an interaction between flipper length and bill depth on bill length. This may not be a terribly sensible example (and note that weâ€™re skipping the all important step of checking our model!), but it should hopefully illustrate these tools.\nFirst letâ€™s create a linear model.\n\nm &lt;- lm(bill_length_mm ~ flipper_length_mm * bill_depth_mm, data = penguins)\n\nWe can explore the results by looking at the summary() table\n\nsummary(m)\n\n\nCall:\nlm(formula = bill_length_mm ~ flipper_length_mm * bill_depth_mm, \n    data = penguins)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-10.6952  -2.5439  -0.2036   2.4788  19.9132 \n\nCoefficients:\n                                Estimate Std. Error t value Pr(&gt;|t|)  \n(Intercept)                     72.14404   49.77162   1.450   0.1481  \nflipper_length_mm               -0.18476    0.24265  -0.761   0.4469  \nbill_depth_mm                   -5.31449    2.93076  -1.813   0.0707 .\nflipper_length_mm:bill_depth_mm  0.02917    0.01439   2.027   0.0434 *\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 3.991 on 338 degrees of freedom\n  (2 observations deleted due to missingness)\nMultiple R-squared:  0.4703,    Adjusted R-squared:  0.4656 \nF-statistic:   100 on 3 and 338 DF,  p-value: &lt; 2.2e-16\n\n\nOr with an Anova() table (here, from the car package, so we can get type III)\n\nAnova(m, type = \"III\")\n\nAnova Table (Type III tests)\n\nResponse: bill_length_mm\n                                Sum Sq  Df F value  Pr(&gt;F)  \n(Intercept)                       33.5   1  2.1011 0.14812  \nflipper_length_mm                  9.2   1  0.5798 0.44694  \nbill_depth_mm                     52.4   1  3.2882 0.07067 .\nflipper_length_mm:bill_depth_mm   65.5   1  4.1103 0.04341 *\nResiduals                       5384.2 338                  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nOkay, in our standard interpretation, we would say that yes, there is an interaction (p = 0.043).\nWith continuous variables, the summary table is often a bit more informative, as we can interpret the estimates. In this case, we can interpret the interaction as: for every 1 mm increase in flipper length, the effect of a 1 mm increase on bill depth increases by 0.029.\nHmm, not incredibly intuitive!\nThe marginalmeans package can be used to explore models with interactions via â€œconditional marginal effectsâ€ and predictions\nConditional marginal effects\nThese are really nice way of visualizing the verbal interpretation we made above.\nWeâ€™ll use the plot_slopes() function to plot the effect of one variable on the slope of the other (i.e.Â an interaction!).\nHere, we look at the effect of bill depth on the slope of flipper length (i.e. the effect of flipper length on our response, bill length).\nThe Y-axis represents the slope of the effect of flipper length on bill depth.\n\nplot_slopes(m, variables = \"flipper_length_mm\", condition = \"bill_depth_mm\") +\n  theme_minimal() +\n  labs(y = \"Slope of flipper length\")\n\n\n\n\n\n\n\nThis figure is a visualization of our interaction parameter, but also puts things into the proper context and includes confidence intervals!\nHere we see that a) the slope is always positive, b) becomes stronger for increasing bill depth.\nPlotting predictions\nWe can plot the predictions to get a visual of this interaction.\n\nplot_predictions(m, condition = list(\"flipper_length_mm\", \"bill_depth_mm\"),\n                 point = 0.5)\n\n\n\n\n\n\n\nHere we can see the various lines (slopes) representing the effect of flipper length on bill length across different bill depths. We see that the effect (slope) increases as bill depth increases (compare the line with bill depth at 21.5 to the one with bill depth at 13.1). This is another visual representation of what we stated above, with additional context. In addition to seeing that all the slopes are positive, and the changes make them stronger, we see this in relation to the original data.\nI find this kind of plot useful for sharing your results as it shows the raw data along with the model results and a clear explanation of what that interaction really means.\nConclusions\nInterpreting interactions can be much simpler with visual aids, and itâ€™s a good idea to use these figures not only for your benefit but for the benefit of anyone youâ€™re sharing your work with.\nYou can make these figures by hand, but using marginalmeans will make it much easier (if slightly less customizable).\nFurther Reading\n\nhttps://vincentarelbundock.github.io/marginaleffects/\nhttps://www.andrewheiss.com/blog/2022/05/20/marginalia/#tldr-overall-summary-of-all-these-marginal-effects-approaches\nSession Info\n\ndevtools::session_info()\n\nâ”€ Session info â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n setting  value\n version  R version 4.3.3 (2024-02-29)\n os       Ubuntu 22.04.4 LTS\n system   x86_64, linux-gnu\n ui       X11\n language en_CA:en\n collate  en_CA.UTF-8\n ctype    en_CA.UTF-8\n tz       America/Winnipeg\n date     2024-03-15\n pandoc   3.1.1 @ /usr/lib/rstudio/resources/app/bin/quarto/bin/tools/ (via rmarkdown)\n\nâ”€ Packages â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n package         * version date (UTC) lib source\n abind             1.4-5   2016-07-21 [1] CRAN (R 4.3.0)\n backports         1.4.1   2021-12-13 [1] CRAN (R 4.3.0)\n cachem            1.0.8   2023-05-01 [1] CRAN (R 4.3.0)\n car             * 3.1-2   2023-03-30 [1] CRAN (R 4.3.0)\n carData         * 3.0-5   2022-01-06 [1] CRAN (R 4.3.0)\n checkmate         2.3.0   2023-10-25 [1] CRAN (R 4.3.1)\n cli               3.6.2   2023-12-11 [1] CRAN (R 4.3.2)\n colorspace        2.1-0   2023-01-23 [1] CRAN (R 4.3.0)\n data.table        1.14.8  2023-02-17 [1] CRAN (R 4.3.0)\n devtools          2.4.5   2022-10-11 [1] CRAN (R 4.3.0)\n digest            0.6.34  2024-01-11 [1] CRAN (R 4.3.2)\n dplyr             1.1.4   2023-11-17 [1] CRAN (R 4.3.2)\n ellipsis          0.3.2   2021-04-29 [1] CRAN (R 4.3.0)\n evaluate          0.23    2023-11-01 [1] CRAN (R 4.3.1)\n fansi             1.0.6   2023-12-08 [1] CRAN (R 4.3.2)\n farver            2.1.1   2022-07-06 [1] CRAN (R 4.3.0)\n fastmap           1.1.1   2023-02-24 [1] CRAN (R 4.3.0)\n fs                1.6.3   2023-07-20 [1] CRAN (R 4.3.1)\n generics          0.1.3   2022-07-05 [1] CRAN (R 4.3.0)\n ggplot2         * 3.5.0   2024-02-23 [1] CRAN (R 4.3.2)\n glue              1.7.0   2024-01-09 [1] CRAN (R 4.3.2)\n gtable            0.3.4   2023-08-21 [1] CRAN (R 4.3.1)\n htmltools         0.5.7   2023-11-03 [1] CRAN (R 4.3.1)\n htmlwidgets       1.6.4   2023-12-06 [1] CRAN (R 4.3.2)\n httpuv            1.6.14  2024-01-26 [1] CRAN (R 4.3.2)\n insight           0.19.6  2023-10-12 [1] CRAN (R 4.3.1)\n jsonlite          1.8.8   2023-12-04 [1] CRAN (R 4.3.2)\n knitr             1.45    2023-10-30 [1] CRAN (R 4.3.1)\n labeling          0.4.3   2023-08-29 [1] CRAN (R 4.3.1)\n later             1.3.2   2023-12-06 [1] CRAN (R 4.3.2)\n lifecycle         1.0.4   2023-11-07 [1] CRAN (R 4.3.2)\n magrittr          2.0.3   2022-03-30 [1] CRAN (R 4.3.0)\n marginaleffects * 0.16.0  2023-10-19 [1] CRAN (R 4.3.1)\n memoise           2.0.1   2021-11-26 [1] CRAN (R 4.3.0)\n mime              0.12    2021-09-28 [1] CRAN (R 4.3.0)\n miniUI            0.1.1.1 2018-05-18 [1] CRAN (R 4.3.0)\n munsell           0.5.0   2018-06-12 [1] CRAN (R 4.3.0)\n palmerpenguins  * 0.1.1   2022-08-15 [1] CRAN (R 4.3.0)\n pillar            1.9.0   2023-03-22 [1] CRAN (R 4.3.0)\n pkgbuild          1.4.3   2023-12-10 [1] CRAN (R 4.3.2)\n pkgconfig         2.0.3   2019-09-22 [1] CRAN (R 4.3.0)\n pkgload           1.3.3   2023-09-22 [1] CRAN (R 4.3.1)\n profvis           0.3.8   2023-05-02 [1] CRAN (R 4.3.1)\n promises          1.2.1   2023-08-10 [1] CRAN (R 4.3.1)\n purrr             1.0.2   2023-08-10 [1] CRAN (R 4.3.1)\n R6                2.5.1   2021-08-19 [1] CRAN (R 4.3.0)\n Rcpp              1.0.12  2024-01-09 [1] CRAN (R 4.3.2)\n remotes           2.4.2.1 2023-07-18 [1] CRAN (R 4.3.2)\n rlang             1.1.3   2024-01-10 [1] CRAN (R 4.3.2)\n rmarkdown         2.25    2023-09-18 [1] CRAN (R 4.3.1)\n rstudioapi        0.15.0  2023-07-07 [1] CRAN (R 4.3.1)\n scales            1.3.0   2023-11-28 [1] CRAN (R 4.3.2)\n sessioninfo       1.2.2   2021-12-06 [1] CRAN (R 4.3.0)\n shiny             1.8.0   2023-11-17 [1] CRAN (R 4.3.2)\n stringi           1.8.3   2023-12-11 [1] CRAN (R 4.3.2)\n stringr           1.5.1   2023-11-14 [1] CRAN (R 4.3.2)\n tibble            3.2.1   2023-03-20 [1] CRAN (R 4.3.0)\n tidyselect        1.2.0   2022-10-10 [1] CRAN (R 4.3.0)\n urlchecker        1.0.1   2021-11-30 [1] CRAN (R 4.3.0)\n usethis           2.2.2   2023-07-06 [1] CRAN (R 4.3.1)\n utf8              1.2.4   2023-10-22 [1] CRAN (R 4.3.1)\n vctrs             0.6.5   2023-12-01 [1] CRAN (R 4.3.2)\n withr             3.0.0   2024-01-16 [1] CRAN (R 4.3.2)\n xfun              0.42    2024-02-08 [1] CRAN (R 4.3.2)\n xtable            1.8-4   2019-04-21 [1] CRAN (R 4.3.0)\n yaml              2.3.8   2023-12-11 [1] CRAN (R 4.3.2)\n\n [1] /home/steffi/R/x86_64-pc-linux-gnu-library/4.3\n [2] /usr/local/lib/R/site-library\n [3] /usr/lib/R/site-library\n [4] /usr/lib/R/library\n\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€"
  },
  {
    "objectID": "posts/ggplot-symbols/index.html",
    "href": "posts/ggplot-symbols/index.html",
    "title": "Special symbols in ggplot2",
    "section": "",
    "text": "Creating ggplot2 figures with special characters such as superscripts (R2) math equations (\\(\\sqrt{x}\\)) or greek letters (\\(\\omega\\), \\(\\lambda\\)), can be a bit of a headache.\nI recently created some figures for my mom which required special characters in the axes as well as in annotations, and it reminded me of how much of a pain it can be, especially because depending on what you want to do, you need to use a different process for it.\nIf you want to create your annotations programatically (e.g., in a column of your data frame), you need a different process than if you were going to create them directly in the ggplot function calls.\nThere are also different layers in ggplots which require different inputs. Some can take an expression, and some only text, so you need to remember what to use for each of those.\nSo I decided to create this note as a reference for my future self, if for no one else ğŸ˜.\nFirst weâ€™ll go over when to use text vs.Â expressions and how to convert between the two for when you use them directly vs.Â programmatically. Then, because thatâ€™s super confusing, weâ€™ll go through a bunch of examples of both."
  },
  {
    "objectID": "posts/ggplot-symbols/index.html#expression-or-text",
    "href": "posts/ggplot-symbols/index.html#expression-or-text",
    "title": "Special symbols in ggplot2",
    "section": "Expression or text?",
    "text": "Expression or text?\nWeâ€™re going to be creating text with special symbols or characters by using plotmath and R expressions. For example, R^2 gives you \\(R^2\\). See ?plotmath or the Appendix table for how to code the symbols or expressions you want to use.\nSometimes ggplot needs this as text, sometimes as an expression.\nFurther, if youâ€™re creating a label directly, itâ€™s generally easier to create it as an expression and convert it to text if you need to.\nOn the other hand, if youâ€™re creating labels programmatically, youâ€™ll generally create them as text and will then have to convert to an expression as required.\nIn a nutshellâ€¦\nFor labels\n\nThis includes name argument in scale_XXX() as well as labs()\n\n\nDirect Use: name = bquote(R^2)\n\n\nProgrammatic Use: name = parse(text = \"R^2\")\n\nFor geoms\n\nThis includes geom_text(), geom_label(), annotate(geom = \"text\") etc.\n\nDirect Use: label = deparse(bquote(R^2)), parse = TRUE1\n\n\nProgrammatic Use: label = \"R^2\", parse = TRUE\n\n\nparse = TRUE tells the function to turn the text into an expression\n\nTo summarize\n\n\n\n\n\n\n\nLayer\nDirect UseCreate with expression\n\nProgrammatic UseCreate with text\n\n\n\n\nlabelrequires expression\nExpressionbquote()\n\nParse text to expressionparse(text = \"\"))\n\n\ngeomrequires text\nDeparse expression to textdeparse(bquote())and use parse = TRUE\n\nText (\"\")and use parse = TRUE"
  },
  {
    "objectID": "posts/ggplot-symbols/index.html#expresssions",
    "href": "posts/ggplot-symbols/index.html#expresssions",
    "title": "Special symbols in ggplot2",
    "section": "Expresssions",
    "text": "Expresssions\nSee ?plotmath or the Appendix table for how to code other symbols or expressions you want to use.\nHere are some suggestionsâ€¦\n\nUse â€œ~â€ to create a space (or two!) between elements\nUse â€œ*â€ to combine different elements without a space (think of this like a â€˜,â€™ in R)\nUse quotes â€œâ€ to mark normal text which has spaces and punctuation\nUse quotes, ~ and * around punctutation as needed (e.g., alpha*\",\"~beta)\nUse == for equals (see Appendix table for more examples)\nUse ''^137*Cs when you need to put superscript before an element\n\n\nbquote(R^2)  # Expression \n\nR^2\n\n\"R^2\"        # Text\n\n[1] \"R^2\"\n\n\nYou can test if you have created a text expression correctly by using parse(text = XXX)\n\nparse(text = \"R^2\")\n\nexpression(R^2)"
  },
  {
    "objectID": "posts/ggplot-symbols/index.html#example-non-dynamic-text-non-programmatic",
    "href": "posts/ggplot-symbols/index.html#example-non-dynamic-text-non-programmatic",
    "title": "Special symbols in ggplot2",
    "section": "Example: Non-dynamic text (non-programmatic)",
    "text": "Example: Non-dynamic text (non-programmatic)\nHere we create various non-dynamic text labels directly in the ggplot() code.\n\nlibrary(ggplot2)\n\nggplot() +\n  theme_bw() +\n  # Use `bquote()` in labels\n  scale_x_continuous(name = bquote(\"Measurement\"~(mu*g/L))) +\n  scale_y_continuous(name = bquote(M/g)) +\n  labs(title = bquote(\"Use quotes to mark normal text\"~(mu*g/L)~(over(mu*g, L))~sqrt(x)),\n       subtitle = bquote(\"Use ~ to link elements together with a space (or more!)\"~~~~~alpha*\",\"~beta*\",\"~Gamma),\n       caption = bquote(sum(x[i], i==1, n))) +\n  # Use `deparse(bquote())` along with `parse = TRUE` in geoms\n  annotate(geom = \"text\", x = 0.5, y = 0.5, label = deparse(bquote(P==0.001*\";\"~R^2==0.45)), parse = TRUE, size = 5) +\n  geom_text(x = 0.5, y = 0.48, aes(label = deparse(bquote(''^137*Cs))), parse = TRUE, size = 5) +\n  geom_text(x = 0.5, y = 0.52, aes(label = deparse(bquote(R[adj]^2==0.41))), parse = TRUE, size = 5)"
  },
  {
    "objectID": "posts/ggplot-symbols/index.html#example-dynamic-text-programmatic",
    "href": "posts/ggplot-symbols/index.html#example-dynamic-text-programmatic",
    "title": "Special symbols in ggplot2",
    "section": "Example: Dynamic text (programmatic)",
    "text": "Example: Dynamic text (programmatic)\nYouâ€™ll want to use dynamic or programmatic labels in situations where your labels are created in a data frame (e.g., different annotations for different facets in a plot, such as \\(R^2\\)s for different models, or special characters in your facet labels). Or perhaps you have a function which creates your plots.\nFirst weâ€™ll create some dynamic content to display. This will be text versions of plotmath expressions.\n\nlibrary(ggplot2)\nlibrary(palmerpenguins) # data\nlibrary(dplyr)  # manipulate the data\n\np &lt;- mutate(penguins, sp = paste0(\"'\", species, \"'[(italic(\", island, \"))]\"))\n\nsamples &lt;- count(p, sp, species, island) |&gt;\n  mutate(label = paste0(\"n['(\", species, \", \", island, \")'] == \", n))\nsamples\n\n# A tibble: 5 Ã— 5\n  sp                            species   island        n label                 \n  &lt;chr&gt;                         &lt;fct&gt;     &lt;fct&gt;     &lt;int&gt; &lt;chr&gt;                 \n1 'Adelie'[(italic(Biscoe))]    Adelie    Biscoe       44 n['(Adelie, Biscoe)']â€¦\n2 'Adelie'[(italic(Dream))]     Adelie    Dream        56 n['(Adelie, Dream)'] â€¦\n3 'Adelie'[(italic(Torgersen))] Adelie    Torgersen    52 n['(Adelie, Torgersenâ€¦\n4 'Chinstrap'[(italic(Dream))]  Chinstrap Dream        68 n['(Chinstrap, Dream)â€¦\n5 'Gentoo'[(italic(Biscoe))]    Gentoo    Biscoe      124 n['(Gentoo, Biscoe)']â€¦\n\nlabels &lt;- list(\"x\" = paste0(\"'Bill Length'~mm[(\", paste0(range(p$year), collapse = \"-\"), \")]\"),\n               \"y\" = paste0(\"'Flipper Length'~mm[(\", paste0(range(p$year), collapse = \"-\"), \")]\"))\nlabels\n\n$x\n[1] \"'Bill Length'~mm[(2007-2009)]\"\n\n$y\n[1] \"'Flipper Length'~mm[(2007-2009)]\"\n\n\nNow letâ€™s add this content to our plot\n\nggplot(data = p, aes(x = bill_length_mm, y = flipper_length_mm)) +\n  geom_point() +\n  geom_text(data = samples, x = -Inf, y = +Inf, aes(label = label), parse = TRUE,\n            hjust = -0.1, vjust = 1.5) +\n  facet_wrap(~ sp, labeller = label_parsed)\n\nWarning: Removed 2 rows containing missing values or values outside the scale range\n(`geom_point()`)."
  },
  {
    "objectID": "posts/ggplot-symbols/index.html#example-dynamic-text---advanced",
    "href": "posts/ggplot-symbols/index.html#example-dynamic-text---advanced",
    "title": "Special symbols in ggplot2",
    "section": "Example: Dynamic text - Advanced",
    "text": "Example: Dynamic text - Advanced\nAs before, letâ€™s start by creating some dynamic content to add to our plots. Weâ€™ll create this by creating text versions of the expressions we want to use.\n\nNote the use of {} around R^2 to ensure that the [adj] is actually subscript to the whole R^2, as opposed to just the the 2 (otherwise youâ€™d get \\(R^{2_{adj}}\\)). Above, we just used a different order, R[adj]^2 to avoid this.\nAlso note that the P-values are formatted to be either &lt;=0.001 or format(nsmall = 3) to ensure there are always three digits after the decimal, and we then put the P-value in quotes (â€™â€™) because it is now text, not a number.\n\n\nlibrary(ggplot2)\nlibrary(palmerpenguins) # data\nlibrary(dplyr)  # manipulate the data\nlibrary(tidyr)  # unnest() to convert nested data back into a regular data frame\nlibrary(purrr)  # map() to loop over models and leables\nlibrary(broom)  # tidy() to extract model information\n\np &lt;- penguins |&gt;\n  add_count(species) |&gt;\n  mutate(sp = paste0(\"'\", species, \"'\"),\n         sp = if_else(species == \"Adelie\", paste0(sp, \"^{1}\"), sp),\n         sp = paste0(sp, \"~(n == frac(\", n, \", \", n(), \"))\"))\n\nstats &lt;- p |&gt;\n  nest(data = -\"sp\") |&gt;\n  mutate(model = map(data, \\(x) lm(flipper_length_mm ~ bill_length_mm, data = x)),\n         labels = map(model, glance)) |&gt;\n  unnest(cols = \"labels\") |&gt;\n  mutate(p_val = round(p.value, 3),\n         p_val = if_else(p.value &lt; 0.001, \"&lt;0.001\", paste0(\"=='\", format(p.value, nsmall = 3), \"'\")),\n         stats = paste0(\"P\", p_val, \"*';'~{R^2}[adj]==\", round(adj.r.squared, 2)))\nselect(stats, sp, stats)\n\n# A tibble: 3 Ã— 2\n  sp                                 stats                       \n  &lt;chr&gt;                              &lt;chr&gt;                       \n1 'Adelie'^{1}~(n == frac(152, 344)) P&lt;0.001*';'~{R^2}[adj]==0.1 \n2 'Gentoo'~(n == frac(124, 344))     P&lt;0.001*';'~{R^2}[adj]==0.43\n3 'Chinstrap'~(n == frac(68, 344))   P&lt;0.001*';'~{R^2}[adj]==0.21\n\nlabels &lt;- list(\"x\" = paste0(\"'Bill Length'~mm[(\", paste0(range(p$year), collapse = \"-\"), \")]\"),\n               \"y\" = paste0(\"'Flipper Length'~mm[(\", paste0(range(p$year), collapse = \"-\"), \")]\"))\nlabels\n\n$x\n[1] \"'Bill Length'~mm[(2007-2009)]\"\n\n$y\n[1] \"'Flipper Length'~mm[(2007-2009)]\"\n\n\nNow letâ€™s add this to our plot\n\nggplot(data = p, aes(x = bill_length_mm, y = flipper_length_mm)) +\n  geom_point() +\n  geom_text(data = stats, x = -Inf, y = +Inf, aes(label = stats), parse = TRUE,\n            hjust = -0.1, vjust = 1.5) +\n  labs(x = parse(text = labels$x),\n       y = parse(text = labels$y),\n       caption = parse(text = \"''^1*'Sampled on all three islands'\")) +\n  scale_y_continuous(limits = \\(x) c(x[1], x[2]*1.04)) +\n  facet_wrap(~ sp, labeller = label_parsed)\n\nWarning: Removed 2 rows containing missing values or values outside the scale range\n(`geom_point()`)."
  },
  {
    "objectID": "posts/ggplot-symbols/index.html#troubleshooting",
    "href": "posts/ggplot-symbols/index.html#troubleshooting",
    "title": "Special symbols in ggplot2",
    "section": "Troubleshooting",
    "text": "Troubleshooting\nErrors\nTo find errors, test your labels with parse().\n\nparse(text = \"R^2\")\n\nexpression(R^2)\n\nparse(text = deparse(bquote(R^2)))\n\nexpression(R^2)\n\nparse(text = p$sp[1])\n\nexpression(\"Adelie\"^{\n    1\n} ~ (n == frac(152, 344)))\n\nparse(text = labels$x)\n\nexpression(\"Bill Length\" ~ mm[(2007 - 2009)])\n\nparse(text = stats$stats[1])\n\nexpression(P &lt; 0.001 * \";\" ~ {\n    R^2\n}[adj] == 0.1)\n\n\nYou can also test them with bquote()\n\nbquote(R^2)\n\nR^2\n\n\nIf you have an error in your label, parse() (or bquote()) will fail.\n\nparse(text = \"R^^2\")\nbquote(R^^2)\n\nError: &lt;text&gt;:2:10: unexpected '^'\n1: parse(text = \"R^^2\")\n2: bquote(R^^\n            ^\n\n\nâ€œunexpected string constantâ€ OR â€œunexpected symbolâ€\n\nDid you remember to use * or ~ between separate elements?\nThis is especially important between text elements\n\n\nparse(text = \"P==0.01';'R^2 == 0.45\")\n\nError in parse(text = \"P==0.01';'R^2 == 0.45\"): &lt;text&gt;:1:8: unexpected string constant\n1: P==0.01';'\n           ^\n\nparse(text = \"P==0.01*';'~R^2==0.45\")\n\nexpression(P == 0.01 * \";\" ~ R^2 == 0.45)"
  },
  {
    "objectID": "posts/ggplot-symbols/index.html#table",
    "href": "posts/ggplot-symbols/index.html#table",
    "title": "Special symbols in ggplot2",
    "section": "Appendix: Plot math demos",
    "text": "Appendix: Plot math demos\nIf you run demo(\"plotmath\"), youâ€™ll get a series of tables showing the outputs of the plotmath codes in plots. However I donâ€™t really like them, so here is my recreation using gt and ggplot2 (and some hacking of the documentation).\nNote that there are some symbols that appear as white squares (especially lower in the table). This means that the font Iâ€™m using doesnâ€™t support those symbols. If you get the same on a symbol you want to use, see about switching up your fonts. Unfortunately that is non-trivial ğŸ˜¢.\nCodelibrary(showtext)\nlibrary(stringr)\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(purrr)\nlibrary(ggplot2)\nlibrary(gt)\n\n# Get the table\ndocs &lt;- tools:::fetchRdDB(file.path(system.file(\"help\", package = \"grDevices\"), \"grDevices\"))\ndocs &lt;- docs$plotmath\ndocs &lt;- capture.output(docs)\ndocs &lt;- docs[-seq(1, str_which(docs, \"\\\\\\\\tabular\\\\{ll\\\\}(?s).*\"), 1)]\ndocs &lt;- docs[-seq(str_which(docs, \"^( )+\\\\}$\")[1], length(docs), 1)]\n\n# Extract the code and descriptions\nlabels &lt;- docs |&gt; \n  str_remove(\"\\\\\\\\cr\") |&gt;\n  str_subset(\"Syntax\", negate = TRUE) |&gt;\n  str_replace_all(\"\\\"\", \"'\") |&gt;\n  str_squish() |&gt;\n  tibble(txt = _) |&gt;\n  filter(txt != \"\") |&gt;\n  separate(\"txt\", into = c(\"code\", \"meaning\"), sep = \" \\\\\\\\tab \") |&gt;\n  mutate(code_raw = str_replace_all(code, \"(\\\\\\\\code\\\\{)([^\\\\}]*)(\\\\})\", \"\\\\2\"),\n         code = paste0(\"`\", code_raw, \"`\"),\n         plot = 1:n(),\n         code_raw = if_else(code_raw == \"theta1, phi1, sigma1, omega1\",\n                            \"theta1*phi1*sigma1*omega1\", code_raw))\n\n# Create a temp image of each symbol - image to that we get the correct\nsysfonts::font_add(family = \"dejavu\", \n                   regular = \"/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf\",\n                   italic = \"/usr/share/fonts/truetype/dejavu/DejaVuSans-Oblique.ttf\",\n                   bold = \"/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf\",\n                   bolditalic = \"/usr/share/fonts/truetype/dejavu/DejaVuSans-BoldOblique.ttf\"\n                   )\n\ng &lt;- map2(labels$code_raw, labels$plot, \\(x, i) {\n  showtext_auto()\n  ggplot() +\n    theme_void() +\n    geom_text(x = 0.5, y = 0.5, aes(label = x), parse = TRUE, size = 40, family = \"dejavu\")\n})\n\n# Create table of code plus symbol images\ngt(labels) |&gt;\n  text_transform(locations = cells_body(columns = plot),\n                 fn = function(x) ggplot_image(g[as.numeric(x)], height = px(50), aspect_ratio = 2)) |&gt;\n  cols_label(plot = \"Plotted Symbol\",\n             code = \"Code\",\n             meaning = \"Description\") |&gt;\n  cols_hide(code_raw) |&gt;\n  fmt_markdown(code)\n\n\n\n\n\n\n\n\n\nCode\nDescription\nPlotted Symbol\n\n\n\nx + y\nx plus y\n\n\n\nx - y\nx minus y\n\n\n\nx*y\njuxtapose x and y\n\n\n\nx/y\nx forwardslash y\n\n\n\nx %+-% y\nx plus or minus y\n\n\n\nx %/% y\nx divided by y\n\n\n\nx %*% y\nx times y\n\n\n\nx %.% y\nx cdot y\n\n\n\nx[i]\nx subscript i\n\n\n\nx^2\nx superscript 2\n\n\n\npaste(x, y, z)\njuxtapose x, y, and z\n\n\n\nsqrt(x)\nsquare root of x\n\n\n\nsqrt(x, y)\nyth root of x\n\n\n\nx == y\nx equals y\n\n\n\nx != y\nx is not equal to y\n\n\n\nx &lt; y\nx is less than y\n\n\n\nx &lt;= y\nx is less than or equal to y\n\n\n\nx &gt; y\nx is greater than y\n\n\n\nx &gt;= y\nx is greater than or equal to y\n\n\n\n!x\nnot x\n\n\n\nx %~~% y\nx is approximately equal to y\n\n\n\nx %=~% y\nx and y are congruent\n\n\n\nx %==% y\nx is defined as y\n\n\n\nx %prop% y\nx is proportional to y\n\n\n\nx %~% y\nx is distributed as y\n\n\n\nplain(x)\ndraw x in normal font\n\n\n\nbold(x)\ndraw x in bold font\n\n\n\nitalic(x)\ndraw x in italic font\n\n\n\nbolditalic(x)\ndraw x in bolditalic font\n\n\n\nsymbol(x)\ndraw x in symbol font\n\n\n\nlist(x, y, z)\ncomma-separated list\n\n\n\n...\nellipsis (height varies)\n\n\n\ncdots\nellipsis (vertically centred)\n\n\n\nldots\nellipsis (at baseline)\n\n\n\nx %subset% y\nx is a proper subset of y\n\n\n\nx %subseteq% y\nx is a subset of y\n\n\n\nx %notsubset% y\nx is not a subset of y\n\n\n\nx %supset% y\nx is a proper superset of y\n\n\n\nx %supseteq% y\nx is a superset of y\n\n\n\nx %in% y\nx is an element of y\n\n\n\nx %notin% y\nx is not an element of y\n\n\n\nhat(x)\nx with a circumflex\n\n\n\ntilde(x)\nx with a tilde\n\n\n\ndot(x)\nx with a dot\n\n\n\nring(x)\nx with a ring\n\n\n\nbar(xy)\nxy with bar\n\n\n\nwidehat(xy)\nxy with a wide circumflex\n\n\n\nwidetilde(xy)\nxy with a wide tilde\n\n\n\nx %&lt;-&gt;% y\nx double-arrow y\n\n\n\nx %-&gt;% y\nx right-arrow y\n\n\n\nx %&lt;-% y\nx left-arrow y\n\n\n\nx %up% y\nx up-arrow y\n\n\n\nx %down% y\nx down-arrow y\n\n\n\nx %&lt;=&gt;% y\nx is equivalent to y\n\n\n\nx %=&gt;% y\nx implies y\n\n\n\nx %&lt;=% y\ny implies x\n\n\n\nx %dblup% y\nx double-up-arrow y\n\n\n\nx %dbldown% y\nx double-down-arrow y\n\n\n\nalpha -- omega\nGreek symbols\n\n\n\nAlpha -- Omega\nuppercase Greek symbols\n\n\n\ntheta1, phi1, sigma1, omega1\ncursive Greek symbols\n\n\n\nUpsilon1\ncapital upsilon with hook\n\n\n\naleph\nfirst letter of Hebrew alphabet\n\n\n\ninfinity\ninfinity symbol\n\n\n\npartialdiff\npartial differential symbol\n\n\n\nnabla\nnabla, gradient symbol\n\n\n\n32*degree\n32 degrees\n\n\n\n60*minute\n60 minutes of angle\n\n\n\n30*second\n30 seconds of angle\n\n\n\ndisplaystyle(x)\ndraw x in normal size (extra spacing)\n\n\n\ntextstyle(x)\ndraw x in normal size\n\n\n\nscriptstyle(x)\ndraw x in small size\n\n\n\nscriptscriptstyle(x)\ndraw x in very small size\n\n\n\nunderline(x)\ndraw x underlined\n\n\n\nx ~~ y\nput extra space between x and y\n\n\n\nx + phantom(0) + y\nleave gap for '0', but don't draw it\n\n\n\nx + over(1, phantom(0))\nleave vertical gap for '0' (don't draw)\n\n\n\nfrac(x, y)\nx over y\n\n\n\nover(x, y)\nx over y\n\n\n\natop(x, y)\nx over y (no horizontal bar)\n\n\n\nsum(x[i], i==1, n)\nsum x[i] for i equals 1 to n\n\n\n\nprod(plain(P)(X==x), x)\nproduct of P(X=x) for all values of x\n\n\n\nintegral(f(x)*dx, a, b)\ndefinite integral of f(x) wrt x\n\n\n\nunion(A[i], i==1, n)\nunion of A[i] for i equals 1 to n\n\n\n\nintersect(A[i], i==1, n)\nintersection of A[i]\n\n\n\nlim(f(x), x %-&gt;% 0)\nlimit of f(x) as x tends to 0\n\n\n\nmin(g(x), x &gt; 0)\nminimum of g(x) for x greater than 0\n\n\n\ninf(S)\ninfimum of S\n\n\n\nsup(S)\nsupremum of S\n\n\n\nx^y + z\nnormal operator precedence\n\n\n\nx^(y + z)\nvisible grouping of operands\n\n\n\nx^{y + z}\ninvisible grouping of operands\n\n\n\ngroup('(',list(a, b),']')\nspecify left and right delimiters\n\n\n\nbgroup('(',atop(x,y),')')\nuse scalable delimiters\n\n\n\ngroup(lceil, x, rceil)\nspecial delimiters\n\n\n\ngroup(lfloor, x, rfloor)\nspecial delimiters\n\n\n\ngroup(langle, list(x, y), rangle)\nspecial delimiters"
  },
  {
    "objectID": "posts/ggplot-symbols/index.html#resources",
    "href": "posts/ggplot-symbols/index.html#resources",
    "title": "Special symbols in ggplot2",
    "section": "Resources",
    "text": "Resources\n\nggplot2::geom_text()\nStackoverflow question"
  },
  {
    "objectID": "posts/ggplot-symbols/index.html#footnotes",
    "href": "posts/ggplot-symbols/index.html#footnotes",
    "title": "Special symbols in ggplot2",
    "section": "Footnotes",
    "text": "Footnotes\n\nYou could also use straight text â€œR^2â€ without deparse(bquote()) if you wanted to work with text.â†©ï¸"
  },
  {
    "objectID": "posts/dharma/index.html",
    "href": "posts/dharma/index.html",
    "title": "DHARMa - Diagnostics for General Linear Models",
    "section": "",
    "text": "DHARMa is a great R package for checking model diagnostics, especially for models that are typically hard to evaluate (e.g., glms etc.).\nSimulated Residuals\nDHARMa works by simulating residuals.\nThis figure (from the DHARMa tutorial) is an illustration of how the residuals are calculatedâ€¦\n\n\n\n\n\n\nIf your data perfectly matched your model, what would the values look like?\n\nPink histogram values show repeatedly simulated values expected\n\n\nHow do your actual values compare?\n\nBlack arrow on x-axis shows actual value\nBlack arrow on y-axis shows residual calculated\nResiduals calculated by where observation lies on cumulative density of simulated values\n\n\nResiduals are scaled (0 to 1)\n\nIf data fits model perfectly, expect all residuals ~ 0.5\nTherefore, a good fit is always = flat/uniform distribution\n\n\nInterpreting Residuals\nIf your data fits the model\n\nResiduals follow a flat (uniform) distribution (no matter what model!)\n\nExpect: Straight line on QQ plot of uniform distribution (similar to QQ Normal plot)\n\nExpect: No patterns between residuals and model predictions (similar to heteroscedasticity plot, resid vs.Â fitted)\n\n\n\n\n\n\n\n\n\n\n\nNote:\nThese arenâ€™t the same residual plots that one would usually use to assess model fit, but you can interpret them in a similar manner, when looking for problems\n\nCloser Look at QQ Plots\n\nVisual check of uniform distribution (expect points to match line)\nTests Uniformity with Kolmogorov-Smirnov (KS) test (Uniform distribution)\nTests for Over/Underdispersion with Dispersion Test\nTests for more Outliers than expected with Outlier test\n\n\n\n\n\n\n\n\n\nCloser Look at Residuals vs.Â Predicted Plots\n\nCheck distribution of residuals (visually and with quantile tests)\n\nDotted lines show expected quantiles\nBlack lines show simulated quantiles (want straight lines)\n\nOutliers would show up as red stars\n\n\n\n\n\n\n\n\n\nUsage\n\nlibrary(DHARMa)\nlibrary(palmerpenguins)\n\nm &lt;- lm(body_mass_g ~ flipper_length_mm, data = penguins)\nr &lt;- simulateResiduals(m, n = 1000, plot = TRUE)\n\n\n\nsimulateResiduals() function from\nUse plot = TRUE to produce diagnostic plots to see if simulated match expectation\n\nn = 1000 isnâ€™t strictly necessary but runs more simulations to produce more stable results\nApplicable to Most Linear Models\n\nREMEMBER! Not assessing residuals in the traditional wayâ€¦\nAssessing whether residuals fit expected pattern given this model\nThis includes assumptions, but also includes general fit, etc.\nSo, we can use this to see if our model could be improvedâ€¦\nAnd we can use DHARMa to test various different types of models\n\nFor example, binomial models\n\npenguins &lt;- mutate(penguins, \n                   size = flipper_length_mm &gt; median(flipper_length_mm, na.rm = TRUE))\n\nm &lt;- glm(size ~ species, family = \"binomial\", data = penguins)\nr &lt;- simulateResiduals(m, plot = TRUE)\n\n\n\n\n\n\n\nOther Tests\nIn addition to testing for outliers, over/underdispersion, etc., DHARMa also has tests for zero-inflation.\nBut important to remember thatâ€¦\n\nzero-inflation may also appear as iffy residuals\noverdispersion can lead to false positives (so address overdispersion first)\n\n\ntestZeroInflation(m)\n\n\n\n\n\n\n\n\n    DHARMa zero-inflation test via comparison to expected zeros with\n    simulation under H0 = fitted model\n\ndata:  simulationOutput\nratioObsSim = 0.99699, p-value = 1\nalternative hypothesis: two.sided\n\n\nResources\n\n\nDHARMa Tutorial (Many great examples of model checking)\n\nSession Info\n\ndevtools::session_info()\n\nâ”€ Session info â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n setting  value\n version  R version 4.3.1 (2023-06-16)\n os       Ubuntu 22.04.3 LTS\n system   x86_64, linux-gnu\n ui       X11\n language en_CA:en\n collate  en_CA.UTF-8\n ctype    en_CA.UTF-8\n tz       America/Winnipeg\n date     2023-09-04\n pandoc   3.1.1 @ /usr/lib/rstudio/resources/app/bin/quarto/bin/tools/ (via rmarkdown)\n\nâ”€ Packages â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n package        * version date (UTC) lib source\n bit              4.0.5   2022-11-15 [1] CRAN (R 4.3.0)\n bit64            4.0.5   2020-08-30 [1] CRAN (R 4.3.0)\n boot             1.3-28  2021-05-03 [4] CRAN (R 4.2.0)\n cachem           1.0.8   2023-05-01 [1] CRAN (R 4.3.0)\n callr            3.7.3   2022-11-02 [1] CRAN (R 4.3.0)\n cli              3.6.1   2023-03-23 [1] CRAN (R 4.3.0)\n codetools        0.2-19  2023-02-01 [4] CRAN (R 4.2.2)\n crayon           1.5.2   2022-09-29 [1] CRAN (R 4.3.0)\n curl             5.0.0   2023-01-12 [1] CRAN (R 4.3.0)\n devtools         2.4.5   2022-10-11 [1] CRAN (R 4.3.0)\n DHARMa         * 0.4.6   2022-09-08 [1] CRAN (R 4.3.1)\n digest           0.6.31  2022-12-11 [1] CRAN (R 4.3.0)\n doParallel       1.0.17  2022-02-07 [1] CRAN (R 4.3.1)\n dplyr          * 1.1.2   2023-04-20 [1] CRAN (R 4.3.0)\n ellipsis         0.3.2   2021-04-29 [1] CRAN (R 4.3.0)\n evaluate         0.20    2023-01-17 [1] CRAN (R 4.3.0)\n fansi            1.0.4   2023-01-22 [1] CRAN (R 4.3.0)\n fastmap          1.1.1   2023-02-24 [1] CRAN (R 4.3.0)\n foreach          1.5.2   2022-02-02 [1] CRAN (R 4.3.0)\n fs               1.6.2   2023-04-25 [1] CRAN (R 4.3.0)\n gap              1.5-3   2023-08-26 [1] CRAN (R 4.3.1)\n gap.datasets     0.0.6   2023-08-25 [1] CRAN (R 4.3.1)\n generics         0.1.3   2022-07-05 [1] CRAN (R 4.3.0)\n glue             1.6.2   2022-02-24 [1] CRAN (R 4.3.0)\n hms              1.1.3   2023-03-21 [1] CRAN (R 4.3.0)\n htmltools        0.5.5   2023-03-23 [1] CRAN (R 4.3.0)\n htmlwidgets      1.6.2   2023-03-17 [1] CRAN (R 4.3.0)\n httpuv           1.6.9   2023-02-14 [1] CRAN (R 4.3.0)\n iterators        1.0.14  2022-02-05 [1] CRAN (R 4.3.0)\n jsonlite         1.8.4   2022-12-06 [1] CRAN (R 4.3.0)\n knitr            1.42    2023-01-25 [1] CRAN (R 4.3.0)\n later            1.3.0   2021-08-18 [1] CRAN (R 4.3.0)\n lattice          0.21-8  2023-04-05 [4] CRAN (R 4.3.0)\n lifecycle        1.0.3   2022-10-07 [1] CRAN (R 4.3.0)\n lme4             1.1-33  2023-04-25 [1] CRAN (R 4.3.0)\n magrittr         2.0.3   2022-03-30 [1] CRAN (R 4.3.0)\n MASS             7.3-60  2023-05-04 [4] CRAN (R 4.3.1)\n Matrix           1.6-0   2023-07-08 [4] CRAN (R 4.3.1)\n memoise          2.0.1   2021-11-26 [1] CRAN (R 4.3.0)\n mgcv             1.9-0   2023-07-11 [4] CRAN (R 4.3.1)\n mime             0.12    2021-09-28 [1] CRAN (R 4.3.0)\n miniUI           0.1.1.1 2018-05-18 [1] CRAN (R 4.3.0)\n minqa            1.2.5   2022-10-19 [1] CRAN (R 4.3.0)\n nlme             3.1-162 2023-01-31 [4] CRAN (R 4.2.2)\n nloptr           2.0.3   2022-05-26 [1] CRAN (R 4.3.0)\n palmerpenguins * 0.1.1   2022-08-15 [1] CRAN (R 4.3.0)\n pillar           1.9.0   2023-03-22 [1] CRAN (R 4.3.0)\n pkgbuild         1.4.0   2022-11-27 [1] CRAN (R 4.3.0)\n pkgconfig        2.0.3   2019-09-22 [1] CRAN (R 4.3.0)\n pkgload          1.3.2   2022-11-16 [1] CRAN (R 4.3.0)\n plyr             1.8.8   2022-11-11 [1] CRAN (R 4.3.0)\n prettyunits      1.1.1   2020-01-24 [1] CRAN (R 4.3.0)\n processx         3.8.1   2023-04-18 [1] CRAN (R 4.3.0)\n profvis          0.3.7   2020-11-02 [1] CRAN (R 4.3.0)\n promises         1.2.0.1 2021-02-11 [1] CRAN (R 4.3.0)\n ps               1.7.5   2023-04-18 [1] CRAN (R 4.3.0)\n purrr            1.0.1   2023-01-10 [1] CRAN (R 4.3.0)\n qgam             1.3.4   2021-11-22 [1] CRAN (R 4.3.1)\n R6               2.5.1   2021-08-19 [1] CRAN (R 4.3.0)\n rbibutils        2.2.15  2023-08-21 [1] CRAN (R 4.3.1)\n Rcpp             1.0.10  2023-01-22 [1] CRAN (R 4.3.0)\n Rdpack           2.5     2023-08-21 [1] CRAN (R 4.3.1)\n readr          * 2.1.4   2023-02-10 [1] CRAN (R 4.3.0)\n remotes          2.4.2   2021-11-30 [1] CRAN (R 4.3.0)\n rlang            1.1.1   2023-04-28 [1] CRAN (R 4.3.0)\n rmarkdown        2.21    2023-03-26 [1] CRAN (R 4.3.0)\n rstudioapi       0.14    2022-08-22 [1] CRAN (R 4.3.0)\n sessioninfo      1.2.2   2021-12-06 [1] CRAN (R 4.3.0)\n shiny            1.7.4   2022-12-15 [1] CRAN (R 4.3.0)\n stringi          1.7.12  2023-01-11 [1] CRAN (R 4.3.0)\n stringr          1.5.0   2022-12-02 [1] CRAN (R 4.3.0)\n tibble           3.2.1   2023-03-20 [1] CRAN (R 4.3.0)\n tidyselect       1.2.0   2022-10-10 [1] CRAN (R 4.3.0)\n tzdb             0.3.0   2022-03-28 [1] CRAN (R 4.3.0)\n urlchecker       1.0.1   2021-11-30 [1] CRAN (R 4.3.0)\n usethis          2.2.0   2023-06-06 [1] CRAN (R 4.3.0)\n utf8             1.2.3   2023-01-31 [1] CRAN (R 4.3.0)\n vctrs            0.6.2   2023-04-19 [1] CRAN (R 4.3.0)\n vroom            1.6.3   2023-04-28 [1] CRAN (R 4.3.0)\n xfun             0.39    2023-04-20 [1] CRAN (R 4.3.0)\n xtable           1.8-4   2019-04-21 [1] CRAN (R 4.3.0)\n yaml             2.3.7   2023-01-23 [1] CRAN (R 4.3.0)\n\n [1] /home/steffi/R/x86_64-pc-linux-gnu-library/4.3\n [2] /usr/local/lib/R/site-library\n [3] /usr/lib/R/site-library\n [4] /usr/lib/R/library\n\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Dr.Â Steffi LaZerte",
    "section": "",
    "text": "Hi! Iâ€™m Steffi LaZerte, an independent biological consultant and R programmer, and part time Community Assistant at rOpenSci.\nI provide services in R Package Development, R Workflows (including data management and analysis), and R Instruction. If you are interested in any of these services, please feel free to contact me."
  },
  {
    "objectID": "index.html#services",
    "href": "index.html#services",
    "title": "Dr.Â Steffi LaZerte",
    "section": "Services",
    "text": "Services\n\nR Package Development\nI am the author of several R packages providing a variety of services from accessing historical weather data from Environment and Climate Change Canadaâ€™s website (weathercan) to accessing NatureCounts animal observations (naturecounts).\nI also help update existing packages, from minor (e.g., rcaaqs) to major (e.g., motus, bbsBayes2, ARUtools) changes.\nI take pride in developing R packages that are not only powerful but user-friendly, including informative errors, in-depth tutorials, and instructions. I also prioritize error checking and testing to ensure packages are robust.\n\n\nR Workflows\nI specialize in preparing data workflows for complex data sets used in the fields of environmental monitoring, conservation, ecology, behaviour, evolution, and other natural sciences (e.g., Aquifer Factsheets). I combine these workflows with Quarto reports and websites as needed to ensure an open and reproducible record (e.g., Weather and Mosquitoes, Vulture Migration, Urban Stopovers and Motus tracks.\nAs a biologist specializing in behavioural ecology I also have the training to consider experimental and statistical protocols, biological relevance and other necessary considerations when preparing data for analysis.\n\n\nR Workshops\nThe power of R to manage and visualize data, to create reports, and perform reproducible statistics is immense. However, the learning curve is fairly steep to start out. I aim to help reduce this learning curve by explaining R in ways that make sense to non-programmers. I also help explain workflows and general best-practices. There is so much more to R than simply statistics. I run workshops on Dealing with Data in R, Introduction to Rmarkdown/Quarto for Reproducibility, and an introductory workshop to Figures in R.\n\nCreated with Quarto by Steffi LaZerte; Updated 2024-06-17"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Steffi LaZerte, MSc, PhD",
    "section": "",
    "text": "Brandon, Manitoba\nCanada, R7A3C4\nPhone: 204-717-1720\nEmail: sel@steffilazerte.ca\nTwitter: @steffilazerte\nMastodon: @steffilazerte@fosstodon.org\nResearchGate: http://www.researchgate.net/profile/Stefanie_LaZerte\nORCID: http://orcid.org/0000-0002-7690-8360\nGitHub: https://github.com/steffilazerte\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBorn and bred in Muskoka, Ontario I am a consulting biologist and R programmer and rOpenSci Community Assistant. I develop R packages and create R workflows in a variety of disciplines in the Natural Sciences.\nBeyond R, Iâ€™m a behavioural ecologist with an interest in how humans influence behaviour of animals and how citizen science projects can be used to do great science and engage the public.\nI enjoy teaching and outreach and try to spread the love of R and make science more accessible.\nOutside of work, I love travelling, be it camping locally (with my kitties!) or flying to visit more distant destinations. But I also enjoy stay-at-home activities such as reading, gardening and spinning wool into yarn.\n\nI was honoured to receive the Society of Canadian Ornithologists/SociÃ©tÃ© des ornithologistes du Canadaâ€™s inaugural Early Career Research Award for 2017\n\n\n\nBeyond a place of work\nI live in Brandon, Manitoba, a beautiful place with a long history, both natural and cultural that I wish to acknowledge and cherish.\nI appreciate that territorial acknowledgements can be complex and can sometimes be seen as insincere, a quick and easy way of appeasing Truth and Reconciliation.\nHowever, to me, an acknowledgement is a part of reconciliation. It isnâ€™t the final step, itâ€™s a first step.\nAs such, I would like to acknowledge that I live and work in Treaty 2 territory which is the traditional territory of the Dakota, Anishanabek, Oji-Cree, Cree, and Dene peoples as well as the homeland of the MÃ©tis Nation.\nI love this area and am privileged to live and work here!"
  },
  {
    "objectID": "R.html",
    "href": "R.html",
    "title": "R Projects",
    "section": "",
    "text": "ARUtools\nJan 2023 - Mar 2024CWS Ontarioâ€™s preferred approach to sampling Boreal BirdsContributor for David Hope, Canadian Wildlife Service â€“ Ontario Region (Ottawa, ON)\n\n\nBASSr\nNov 2022 - Mar 2024Facilitate the processing of ARU data and subsampling of recordingsContributor for David Hope, Canadian Wildlife Service â€“ Ontario Region (Ottawa, ON)\n\n\nbbsBayes / bbsBayes2\nAug 2022 - Jan 2023Bayesian modelling of Breeding Bird Survey DataContributor for Adam Smith, Environment and Climate Change Canada (Ottawa, ON)\n\n\nfasstrshiny\nJan 2022 - Mar 2022A Shiny app to analyze, summarize, and visualize daily streamflow dataContributor (Shiny App) for Jon Goetz, British Columbia Ministry of Water, Land and Resource Stewardship (Victoria, BC)\n\n\nmoosecounter\nSep 2021 - PresentFor conducting adaptive moose surveysContributor (Shiny App) for PÃ©ter SÃ³lymos, Analythium Solutions Inc.Â (Edmonton, AB)\n\n\nbcgwlreports\nMar 2021 - PresentAutomatically creating HTML groundwater level reports for assessing potential flood and drought conditionsCreator/Contributor for Jon Goetz, British Columbia Ministry of Water, Land and Resource Stewardship (Victoria, BC)\n\n\nbcaquiferdata\nJan 2021 - PresentProcess BC Gov GWELLS data into formats more suitable for other analyses (e.g., Strater, Voxler, ArcHydro), including Shiny App.Creator/Maintainer for Christine Bieber, British Columbia Ministry of Water, Land and Resource Stewardship (Victoria, BC)\n\n\nmotus\nJan 2019 - PresentAccessing MOTUS dataContributor/Maintainer for Denis LePage, Birds Canada (Port Rowan, ON)\n\n\nnaturecounts\nJan 2019 - PresentAccessing data from the NatureCounts platform by Birds CanadaCreator/Maintainer for Denis LePage, Birds Canada (Port Rowan, ON)\n\n\ncavityuse\nAug 2018 - PresentDetect use of cavities (caves, burrows, etc.) from geolocator data in a variety of animal species.Creator/Maintainer, Independent Development \n\n\nrcaaqs\nNov 2017 - Feb 2018Facilitate the calculation of air quality metrics according to the Canadian Ambient Air Quality Standards (CAAQS)Contributor for Stephanie Hazlitt, British Columbia Ministry of Environment and Climate Change Strategy (Victoria, BC)\n\n\nbcgroundwater\nNov 2017 - Feb 2018Facilitate analysis and visualisation of groundwater data from the British Columbia Provincial Groundwater Observation Well Network.Contributor for Stephanie Hazlitt, British Columbia Ministry of Environment and Climate Change Strategy (Victoria, BC)\n\n\nLITAP\nMay 2017 - PresentAnalysis of waterflow based on elevation data and pit removalsCreator/Maintainer for Sheng Li, Agriculture and Agri-Food Canada (Fredericton, NB)\n\n\nbcgwcat\nJan 2017 - PresentProvides easy access to EMS data as well as tools specific to those working with groundwater through R functions but also through a Shiny App user-interfaceCreator/Maintainer for Julie-Ann Ishikawa & Andarge Baye, British Columbia Ministry of Water, Land and Resource Stewardship (Victoria, BC)\n\n\nweathercan\nJun 2016 - PresentPeer-reviewed R package for downloading Canadian weather data from Environment and Climate Change Canada. Part of rOpenSciCreator/Maintainer, Independent Development \n\n\nfeedr\nJan 2016 - PresentLoading, transforming and visualizing RFID data created when pit-tagged animals are detected by RFID loggersCreator/Maintainer; Post-doctoral work for David Hill, Thompson Rivers University (Kamloops, BC)"
  },
  {
    "objectID": "R.html#package-developement",
    "href": "R.html#package-developement",
    "title": "R Projects",
    "section": "",
    "text": "ARUtools\nJan 2023 - Mar 2024CWS Ontarioâ€™s preferred approach to sampling Boreal BirdsContributor for David Hope, Canadian Wildlife Service â€“ Ontario Region (Ottawa, ON)\n\n\nBASSr\nNov 2022 - Mar 2024Facilitate the processing of ARU data and subsampling of recordingsContributor for David Hope, Canadian Wildlife Service â€“ Ontario Region (Ottawa, ON)\n\n\nbbsBayes / bbsBayes2\nAug 2022 - Jan 2023Bayesian modelling of Breeding Bird Survey DataContributor for Adam Smith, Environment and Climate Change Canada (Ottawa, ON)\n\n\nfasstrshiny\nJan 2022 - Mar 2022A Shiny app to analyze, summarize, and visualize daily streamflow dataContributor (Shiny App) for Jon Goetz, British Columbia Ministry of Water, Land and Resource Stewardship (Victoria, BC)\n\n\nmoosecounter\nSep 2021 - PresentFor conducting adaptive moose surveysContributor (Shiny App) for PÃ©ter SÃ³lymos, Analythium Solutions Inc.Â (Edmonton, AB)\n\n\nbcgwlreports\nMar 2021 - PresentAutomatically creating HTML groundwater level reports for assessing potential flood and drought conditionsCreator/Contributor for Jon Goetz, British Columbia Ministry of Water, Land and Resource Stewardship (Victoria, BC)\n\n\nbcaquiferdata\nJan 2021 - PresentProcess BC Gov GWELLS data into formats more suitable for other analyses (e.g., Strater, Voxler, ArcHydro), including Shiny App.Creator/Maintainer for Christine Bieber, British Columbia Ministry of Water, Land and Resource Stewardship (Victoria, BC)\n\n\nmotus\nJan 2019 - PresentAccessing MOTUS dataContributor/Maintainer for Denis LePage, Birds Canada (Port Rowan, ON)\n\n\nnaturecounts\nJan 2019 - PresentAccessing data from the NatureCounts platform by Birds CanadaCreator/Maintainer for Denis LePage, Birds Canada (Port Rowan, ON)\n\n\ncavityuse\nAug 2018 - PresentDetect use of cavities (caves, burrows, etc.) from geolocator data in a variety of animal species.Creator/Maintainer, Independent Development \n\n\nrcaaqs\nNov 2017 - Feb 2018Facilitate the calculation of air quality metrics according to the Canadian Ambient Air Quality Standards (CAAQS)Contributor for Stephanie Hazlitt, British Columbia Ministry of Environment and Climate Change Strategy (Victoria, BC)\n\n\nbcgroundwater\nNov 2017 - Feb 2018Facilitate analysis and visualisation of groundwater data from the British Columbia Provincial Groundwater Observation Well Network.Contributor for Stephanie Hazlitt, British Columbia Ministry of Environment and Climate Change Strategy (Victoria, BC)\n\n\nLITAP\nMay 2017 - PresentAnalysis of waterflow based on elevation data and pit removalsCreator/Maintainer for Sheng Li, Agriculture and Agri-Food Canada (Fredericton, NB)\n\n\nbcgwcat\nJan 2017 - PresentProvides easy access to EMS data as well as tools specific to those working with groundwater through R functions but also through a Shiny App user-interfaceCreator/Maintainer for Julie-Ann Ishikawa & Andarge Baye, British Columbia Ministry of Water, Land and Resource Stewardship (Victoria, BC)\n\n\nweathercan\nJun 2016 - PresentPeer-reviewed R package for downloading Canadian weather data from Environment and Climate Change Canada. Part of rOpenSciCreator/Maintainer, Independent Development \n\n\nfeedr\nJan 2016 - PresentLoading, transforming and visualizing RFID data created when pit-tagged animals are detected by RFID loggersCreator/Maintainer; Post-doctoral work for David Hill, Thompson Rivers University (Kamloops, BC)"
  },
  {
    "objectID": "R.html#r-script-development-and-analysis",
    "href": "R.html#r-script-development-and-analysis",
    "title": "R Projects",
    "section": "R Script Development and Analysis",
    "text": "R Script Development and Analysis\n\n\n\n\n\n\n\n\n\n\n\n\nAssessing use of urban stopovers with Motus\nJan 2024 - Mar 2024 Barbara Frei, Environment and Climate Change Canada (Montreal, QC)\n\n\nSO2, NO2, Ozone and PM2.5 CAAQS indicators\nFeb 2022 - Mar 2022 Karly Harker, British Columbia Ministry of Environment and Climate Change Strategy (Victoria, BC)\n\n\nFungi communities on ant mounds\nMar 2021 - Sep 2021 Wendy Untereiner, Brandon University (Brandon, MB)\n\n\nBC Protected Areas Shiny App interactive map development\nMar 2021 - Mar 2021 Andy Teucher, British Columbia Ministry of Environment and Climate Change Strategy (Victoria, BC)\n\n\nCavity use of red-headed woodpeckers\nJan 2021 - Aug 2022 Elena West, Audubon Society (Minneapolis, USA)\n\n\nRattlesnake hibernation\nDec 2020 - Oct 2021 Karl Larsen, Thompson Rivers University (Kamloops, BC)\n\n\nWireworms and temperature\nDec 2020 - Jul 2021 Bryan Cassone, Brandon University (Brandon, MB)\n\n\nBird song playback and SNR extraction\nJul 2020 - Dec 2020 Ken Otter, University of Northern BC (Prince George, BC)\n\n\nTutoring mixed models and power analysis\nMay 2020 - Jun 2020 Catherine Ortner, Thompson Rivers University (Kamloops, BC)\n\n\nMigration in aerial insectivores and movements in Long-billed Curlews\nDec 2019 - Nov 2023 Matt Reudink, Thompson Rivers University (Kamloops, BC)\n\n\nBC Groundwater levels indicator interactive map development\nOct 2018 - Oct 2018 Stephanie Hazlitt, British Columbia Ministry of Environment and Climate Change Strategy (Victoria, BC)\n\n\nOzone and PM2.5 CAAQS indicators\nAug 2018 - Aug 2018 Stephanie Hazlitt, British Columbia Ministry of Environment and Climate Change Strategy (Victoria, BC)\n\n\nAquifer factsheets: R programming, tutoring and workshops\nNov 2017 - Present Julie-Ann Ishikawa & Andarge Baye, British Columbia Ministry of Water, Land and Resource Stewardship (Victoria, BC)\n\n\nPhysiological ecology of sedges\nSep 2017 - Jul 2020 Martin J. Lechowicz, McGill University (Montreal, QC)\n\n\nPopulation decline of aerial insectivores\nMay 2017 - Aug 2017 Joe Nocera, University of New Brunswick (Fredericton, NB)\n\n\nBull trout Telemetry: Data cleaning, preparation, R training\nJan 2017 - Jan 2017 Ian Spendlow, British Columbia Ministry of Forests, Lands and Natural Resource Operations (Prince George, BC)\n\n\nWhite-throated sparrow song variation (Citizen Science)\nJan 2016 - Jan 2017Post-doctoral Researcher for Ken Otter, University of Northern BC (Prince George, BC)\n\n\nCommunication and noise in mountain chickadees\nMay 2015 - Sep 2015Post-doctoral Researcher for Ken Otter, University of Northern BC (Prince George, BC)"
  },
  {
    "objectID": "R.html#r-workshops",
    "href": "R.html#r-workshops",
    "title": "R Projects",
    "section": "R Workshops",
    "text": "R Workshops\n\n\n\n\n\n\n\n\n\n\n\n\n2019-2024\nTwo-day Introduction to R (Instructor) Brandon University (Online, Brandon, MB)\n\n\n2024\nIntroduction to using R Shiny Apps (Instructor) BC Government (Online)\n\n\n2024\nTwo-day Introduction to R (Instructor) BC Government (Online)\n\n\n2019, 2020, 2023\nIntro to R through Figures (Instructor) The Wildlife Society (Online, Winnipeg, MB)\n\n\n2023\nIntroduction to Rmarkdown/Quarto for Reproducibility (Instructor) Birds Canada (Online)\n\n\n2022\nIntroduction to Rmarkdown/Quarto for Reproducibility (Instructor) Society of Canadian Ornithologists / SociÃ©tÃ© des ornithologistes du Canada (Online)\n\n\n2021\nIntro to R through Figures (Instructor) University of Northern BC (Online)\n\n\n2020\nTwo-day Introduction to R (Instructor) University of Manitoba (Winnipeg, MB)"
  },
  {
    "objectID": "R.html#other-r-related-work",
    "href": "R.html#other-r-related-work",
    "title": "R Projects",
    "section": "Other R-related work",
    "text": "Other R-related work\n\n\n\n\n\n\n\n\n\n\n\n\nrOpenSci Community Assistant\nFeb 2020 - PresentAssisting in the maintenance and development of the rOpenSci communityContracted for rOpenSci (Online)\n\n\n\n\n\n\n\nSee my CV for more details on Teaching R, and R Volunteering"
  },
  {
    "objectID": "cv.html",
    "href": "cv.html",
    "title": "Academic Activities & CV",
    "section": "",
    "text": "I was honoured to receive the Society of Canadian Ornithologists/SociÃ©tÃ© des ornithologistes du Canadaâ€™s inaugural Early Career Research Award for 2017"
  },
  {
    "objectID": "cv.html#academic-activities",
    "href": "cv.html#academic-activities",
    "title": "Academic Activities & CV",
    "section": "Academic Activities",
    "text": "Academic Activities\n\nPositions\n2018-Present Adjunct Professor, Department of Biology, Brandon University\n\n\nMSc Committees\n2019-Present Department of Geography & Environment, Brandon University\n2019-Present Department of Biology, Brandon University\n2019-2020 Department of Biological Sciences, University of Manitoba"
  },
  {
    "objectID": "cv.html#education",
    "href": "cv.html#education",
    "title": "Academic Activities & CV",
    "section": "Education",
    "text": "Education\nPhD (2010 â€“ 2015) University of Northern BC, Natural Resources and Environmental Studies\nSupervisor: Dr.Â Ken A. Otter\nThesis: Chickadee vocalizations in human-altered environments\nMSc (2007 â€“ 2010) McGill University, Biology\nSupervisor: Dr.Â Don L. Kramer\nThesis: Using thermosensitive telemetry to measure activity in eastern chipmunks (Tamias striatus)\nBSc (2003 â€“ 2007) University of Toronto, Honours Zoology, Behaviour Specialist\nSupervisor: Dr.Â Allan Baker\nIndependent Project: Genomic scan using AFLPs reveals that red knot subspecies are genetically differentiated"
  },
  {
    "objectID": "cv.html#post-docs",
    "href": "cv.html#post-docs",
    "title": "Academic Activities & CV",
    "section": "Post-Docs",
    "text": "Post-Docs\nPost-Doc (2016 â€“ 2017) Thompson Rivers University, Geography and Environmental Studies\nSupervisor: Dr.Â David J. Hill\nDetails: Developing citizen science tools, in particular an open system for the web-based visualization and analysis of animal movement data\nPost-Doc (2015 â€“ 2016) University of Northern BC, Natural Resources and Environmental Studies\nSupervisor: Dr.Â Ken A. Otter\nDetails: Tracking gap-crossing in small birds through automated RFID feeders.\nPost-Doc (2015) University of Northern BC, Natural Resources and Environmental Studies\nSupervisor: Dr.Â Ken A. Otter\nDetails: A follow up study to playback studies conducted during my PhD looking at audibility of different vocalizations in noisy environments."
  },
  {
    "objectID": "cv.html#publications",
    "href": "cv.html#publications",
    "title": "Academic Activities & CV",
    "section": "Publications",
    "text": "Publications"
  },
  {
    "objectID": "cv.html#presentations",
    "href": "cv.html#presentations",
    "title": "Academic Activities & CV",
    "section": "Presentations",
    "text": "Presentations"
  },
  {
    "objectID": "cv.html#teaching",
    "href": "cv.html#teaching",
    "title": "Academic Activities & CV",
    "section": "Teaching",
    "text": "Teaching\n\nR University Teaching\n\n\n\n\n\n\n\n\n\n\n\n\n2018, 2020, 2021\nNRI 7350 Study design and quantitative methods for resource and environmental management (Sessional Co-Instructor) University of Manitoba (Winnipeg, MB)\n\n\n2017\nSOIL 7240 Preparing Data in R (Module Instructor) University of Manitoba (Winnipeg, MB)\n\n\n2014\nSTAT 473/673 Experimental Design and Analysis (Substitute Instructor) University of Northern BC (Prince George, BC)\n\n\n\n\n\n\n\n\n\nR Workshops\n\n\n\n\n\n\n\n\n\n\n\n\n2019-2024\nTwo-day Introduction to R (Instructor) Brandon University (Online, Brandon, MB)\n\n\n2024\nIntroduction to using R Shiny Apps (Instructor) BC Government (Online)\n\n\n2024\nTwo-day Introduction to R (Instructor) BC Government (Online)\n\n\n2019, 2020, 2023\nIntro to R through Figures (Instructor) The Wildlife Society (Online, Winnipeg, MB)\n\n\n2023\nIntroduction to Rmarkdown/Quarto for Reproducibility (Instructor) Birds Canada (Online)\n\n\n2022\nIntroduction to Rmarkdown/Quarto for Reproducibility (Instructor) Society of Canadian Ornithologists / SociÃ©tÃ© des ornithologistes du Canada (Online)\n\n\n2021\nIntro to R through Figures (Instructor) University of Northern BC (Online)\n\n\n2020\nTwo-day Introduction to R (Instructor) University of Manitoba (Winnipeg, MB)\n\n\n\n\n\n\n\n\n\nR Volunteering\n\n\n\n\n\n\n\n\n\n\n\n\n\n2012\nPresent\nOne-on-one assistance - University of Manitoba, Winnipeg, MB - Brandon University, Brandon, MB - University of New Brunswick, Fredericton, NB - Wilfrid Laurier, Waterloo, ON - University of Northern BC, Prince George, BC\n\n\n2012\n2017\nOrganized R Help Groups - R Group (2016-2017) University of New Brunswick, Fredericton, NB - R Coffee Hour (2012-2016) University of Northern BC, Prince George, BC\n\n\n\n\n\n\n\n\n\nOther University Teaching\n\n\n\n\n\n\n\n\n\n\n\n\n2018\nAnimal Behaviour 15:375 (Guest Lecture) Brandon University (Brandon, MB)\n\n\n2018\nEvolution 15:350 (Guest Lecture) Brandon University (Brandon, MB)\n\n\n2017\nGlobal Environmental Change 38:290 (Guest Lecture) Brandon University (Brandon, MB)\n\n\n2014, 2016\nDrainage Basin Geomorphology GEOG 311 (Guest Lecture) University of Northern BC (Prince George, BC)\n\n\n2014-2016\nAnimal Behaviour BIOL 420 (Guest Lecture) University of Northern BC (Prince George, BC)\n\n\n2015\nAnimal Behaviour BIOL 3101 (Guest Lecture) Thompson Rivers University (Kamloops, BC)\n\n\n2015\nBIOL 323 Evolutionary Biology (Sessional Instructor) University of Northern BC (Prince George, BC)\n\n\n2014\nStat 240 Basic Statistics (Teaching Assistant) University of Northern BC (Prince George, BC)\n\n\n2011\nBiol 102 Introductory Biology II (Teaching Assistant) University of Northern BC (Prince George, BC)\n\n\n2010\nBiol 308 Ornithology and Mammalogy (Teaching Assistant) University of Northern BC (Prince George, BC)\n\n\n2009\nBiol 111 Principles: Organismal Biology (Teaching Assistant) McGill University (Montreal, QC)\n\n\n2008\nBiol 205 Biology of Organisms (Teaching Assistant) McGill University (Montreal, QC)\n\n\n\n\n\n\n\n\nLarge events\n\n2015 UNBC Discovery Centre\nThis centre was a 3-day event held in November 2015. I was one of three coordinators and organized events, volunteers and panelists, and supervised on all event days.\n\n\n\nAttendance at Teaching Conferences and Workshops\n\n\n\n\n\n\n\n\n\n\n\n\n2018-08\nBrandon University Teaching Excellence Conference (Brandon, MB)\n\n\n2011â€“2016\nUNBC and CNC Annual Teaching and Learning Conference (Prince George, BC)\n\n\n2014-09\nTeaching Dossier Workshop (Prince George, BC)\n\n\n2011-08\nInstructional Skills Workshop (Prince George, BC)\n\n\n2011-01\nUNBC Teaching Assistant Workshop (Prince George, BC)\n\n\n2008-03\nMcGill Professional development workshop: Learning to Teach (Montreal, QC)\n\n\n2008-01\nTeaching Workshop â€“ McGill Tomlinson Project in University-Level Science Education (Montreal, QC)\n\n\n\n\n\n\n\n\n\nCommunity presentations and outreach\n\n\n\n\n\n\n\n\n\n\n\n\n2015-01\nPrince George Naturalists Club Guest speaker (Prince George, BC) Singing through the noise: How birds compensate for effects urbanization on communication\n\n\n2013-11\nWilliams Lake Naturalists Club Guest speaker (Williams Lake, BC) Singing through the noise: How birds compensate for effects urbanization on communication\n\n\n2014-05\nPrince George Young Naturalists Club Guest speaker (Prince George, BC) Come learn all about Chickadees!\n\n\n2014-03\nImmaculate Conception School Science Fair Judge (Prince George, BC)\n\n\n2013-11\nLake City Secondary School Science 8 and 9 Guest Educator (Williams Lake, BC) Early bird gets the worm!\n\n\n2013-10\nUNBC Northern Research Group Trail Talks Guest Guide (Prince George, BC) Birds and Glacial Lakes\n\n\n2013-09\nQuesnel River Research Centre High School Salmon Day Guest Scientist (Likely, BC) Chickadee communication and sound transmission activities\n\n\n2012/09 & 2013/09\nKelowna Kokanee Salmon Festival Exhibitor (Kelowna, BC)"
  },
  {
    "objectID": "cv.html#awards-and-scholarships",
    "href": "cv.html#awards-and-scholarships",
    "title": "Academic Activities & CV",
    "section": "Awards and Scholarships",
    "text": "Awards and Scholarships\n\nSCO-SOC Early Career Researcher Award (2017/08)\nNSERC Postgraduate Scholarship (PGS) Doctoral (2011/05 â€“ 2014/05)\nSociety of Canadian Ornithologists (SCO-SOC) First Place Student Presentation (2013/08)\nSociety of Canadian Ornithologists (SCO-SOC) James L. Baillie Award (2012)\nNSERC Alexander Graham Bell Canada Graduate Scholarship (CGS) Masters (2008/04 â€“ 2009/04)\nNSERC Undergraduate Student Research Award (2006)"
  },
  {
    "objectID": "cv.html#media",
    "href": "cv.html#media",
    "title": "Academic Activities & CV",
    "section": "Media",
    "text": "Media\nOver the years several projects Iâ€™ve been involved with have been fortunate enough to attract some media attention.\n\nChickadees and Noise\n\n2016/07 Media attention surrounding publication of â€œLearning to cope: Vocal adjustment to urban noise is correlated with prior experience in black-capped chickadeesâ€\n\nTV: CKPG (watch)\nRadio: CBC Daybreak North (listen)\nNewspaper: Prince George Citizen (read)\nNewsite: 250news.org (read)\n\n2013/09 SCO award for best student presentation highlighted by Ducks Unlimited â€“ Ducks Unlimited facebook post\n2012/04 Sharing relevant findings with the Stanley Park Ecological Society â€“ Stanley Park Ecological Society (read)\n\n\n\nWhite-throated Sparrows Citizen Science\n\n2016/03 Start of the citizen science study â€“ CKPG (watch)\n2016/05 Geolocators and tracking movements â€“ CKPG (watch)"
  },
  {
    "objectID": "posts/basic-models/index.html",
    "href": "posts/basic-models/index.html",
    "title": "Running Basic Linear Models",
    "section": "",
    "text": "In R, basic linear models are run with the lm() function.\n\nlm(y ~ x1 + x2, data = data)\n\nR will choose which type of linear model to do depending on the type of values in x1 and x2.\n\n\nRegression - One continuous predictor (x1 only and is continuous)\n\nMultiple regression - More than one continuous predictor (both x1 and x2 are continuous)\n\nANOVA - Categorical predictor(s) (both x1 and x2 are categorical - factors)\n\nANCOVA - Mix of categorical and continuous predictors (x1 is continuous and x2 is categorical)\n\nIn all cases, y is continuous.\nNo count data, no binary (binomial) data, no proprotions.\n(Although technically sometimes count data is close enough to continuous and proportions can be transformed)\nQuick example\n\nlibrary(palmerpenguins) # To access the penguins data set\nm &lt;- lm(body_mass_g ~ bill_depth_mm, data = penguins)\nm\n\n\nCall:\nlm(formula = body_mass_g ~ bill_depth_mm, data = penguins)\n\nCoefficients:\n  (Intercept)  bill_depth_mm  \n       7488.7         -191.6  \n\n\n\nBut wait! How do I interpret that?\n\nAll the details are stored in the model object m. We can use many other R functions to check our assumptions, summarize the results, or create ANOVA tables.\nBut first, you really should check your Diagnostics!\nSide note on NAâ€™s\nBy default missing values (NAâ€™s) are dropped from the analysis and from the data contained by the model. However, even better is to use na.exclude.\n\nm &lt;- lm(body_mass_g ~ bill_depth_mm, data = penguins, na.action = na.exclude)\n\nThis also excludes missing values (NAâ€™s) from the analysis, but not from the data you extract from the model (which makes it much easier to combine back with your raw data set when performing Diagnostics).\nSession Info\n\ndevtools::session_info()\n\nâ”€ Session info â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n setting  value\n version  R version 4.3.1 (2023-06-16)\n os       Ubuntu 22.04.3 LTS\n system   x86_64, linux-gnu\n ui       X11\n language en_CA:en\n collate  en_CA.UTF-8\n ctype    en_CA.UTF-8\n tz       America/Winnipeg\n date     2023-09-04\n pandoc   3.1.1 @ /usr/lib/rstudio/resources/app/bin/quarto/bin/tools/ (via rmarkdown)\n\nâ”€ Packages â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n package        * version date (UTC) lib source\n cachem           1.0.8   2023-05-01 [1] CRAN (R 4.3.0)\n callr            3.7.3   2022-11-02 [1] CRAN (R 4.3.0)\n cli              3.6.1   2023-03-23 [1] CRAN (R 4.3.0)\n crayon           1.5.2   2022-09-29 [1] CRAN (R 4.3.0)\n devtools         2.4.5   2022-10-11 [1] CRAN (R 4.3.0)\n digest           0.6.31  2022-12-11 [1] CRAN (R 4.3.0)\n ellipsis         0.3.2   2021-04-29 [1] CRAN (R 4.3.0)\n evaluate         0.20    2023-01-17 [1] CRAN (R 4.3.0)\n fansi            1.0.4   2023-01-22 [1] CRAN (R 4.3.0)\n fastmap          1.1.1   2023-02-24 [1] CRAN (R 4.3.0)\n fs               1.6.2   2023-04-25 [1] CRAN (R 4.3.0)\n glue             1.6.2   2022-02-24 [1] CRAN (R 4.3.0)\n htmltools        0.5.5   2023-03-23 [1] CRAN (R 4.3.0)\n htmlwidgets      1.6.2   2023-03-17 [1] CRAN (R 4.3.0)\n httpuv           1.6.9   2023-02-14 [1] CRAN (R 4.3.0)\n jsonlite         1.8.4   2022-12-06 [1] CRAN (R 4.3.0)\n knitr            1.42    2023-01-25 [1] CRAN (R 4.3.0)\n later            1.3.0   2021-08-18 [1] CRAN (R 4.3.0)\n lifecycle        1.0.3   2022-10-07 [1] CRAN (R 4.3.0)\n magrittr         2.0.3   2022-03-30 [1] CRAN (R 4.3.0)\n memoise          2.0.1   2021-11-26 [1] CRAN (R 4.3.0)\n mime             0.12    2021-09-28 [1] CRAN (R 4.3.0)\n miniUI           0.1.1.1 2018-05-18 [1] CRAN (R 4.3.0)\n palmerpenguins * 0.1.1   2022-08-15 [1] CRAN (R 4.3.0)\n pillar           1.9.0   2023-03-22 [1] CRAN (R 4.3.0)\n pkgbuild         1.4.0   2022-11-27 [1] CRAN (R 4.3.0)\n pkgconfig        2.0.3   2019-09-22 [1] CRAN (R 4.3.0)\n pkgload          1.3.2   2022-11-16 [1] CRAN (R 4.3.0)\n prettyunits      1.1.1   2020-01-24 [1] CRAN (R 4.3.0)\n processx         3.8.1   2023-04-18 [1] CRAN (R 4.3.0)\n profvis          0.3.7   2020-11-02 [1] CRAN (R 4.3.0)\n promises         1.2.0.1 2021-02-11 [1] CRAN (R 4.3.0)\n ps               1.7.5   2023-04-18 [1] CRAN (R 4.3.0)\n purrr            1.0.1   2023-01-10 [1] CRAN (R 4.3.0)\n R6               2.5.1   2021-08-19 [1] CRAN (R 4.3.0)\n Rcpp             1.0.10  2023-01-22 [1] CRAN (R 4.3.0)\n remotes          2.4.2   2021-11-30 [1] CRAN (R 4.3.0)\n rlang            1.1.1   2023-04-28 [1] CRAN (R 4.3.0)\n rmarkdown        2.21    2023-03-26 [1] CRAN (R 4.3.0)\n rstudioapi       0.14    2022-08-22 [1] CRAN (R 4.3.0)\n sessioninfo      1.2.2   2021-12-06 [1] CRAN (R 4.3.0)\n shiny            1.7.4   2022-12-15 [1] CRAN (R 4.3.0)\n stringi          1.7.12  2023-01-11 [1] CRAN (R 4.3.0)\n stringr          1.5.0   2022-12-02 [1] CRAN (R 4.3.0)\n tibble           3.2.1   2023-03-20 [1] CRAN (R 4.3.0)\n urlchecker       1.0.1   2021-11-30 [1] CRAN (R 4.3.0)\n usethis          2.2.0   2023-06-06 [1] CRAN (R 4.3.0)\n utf8             1.2.3   2023-01-31 [1] CRAN (R 4.3.0)\n vctrs            0.6.2   2023-04-19 [1] CRAN (R 4.3.0)\n xfun             0.39    2023-04-20 [1] CRAN (R 4.3.0)\n xtable           1.8-4   2019-04-21 [1] CRAN (R 4.3.0)\n yaml             2.3.7   2023-01-23 [1] CRAN (R 4.3.0)\n\n [1] /home/steffi/R/x86_64-pc-linux-gnu-library/4.3\n [2] /usr/local/lib/R/site-library\n [3] /usr/lib/R/site-library\n [4] /usr/lib/R/library\n\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€"
  },
  {
    "objectID": "posts/diagnostics-lm/index.html",
    "href": "posts/diagnostics-lm/index.html",
    "title": "Diagnostics for Simple Linear Models",
    "section": "",
    "text": "All models have assumptions and cautions. Understanding whether youâ€™ve satisfied these assumptions and checking for potential problems are some of the hardest things to do in statistics.\nFor simple linear models (lm()) the main assumptions are\nAnd the main cautions are"
  },
  {
    "objectID": "posts/diagnostics-lm/index.html#footnotes",
    "href": "posts/diagnostics-lm/index.html#footnotes",
    "title": "Diagnostics for Simple Linear Models",
    "section": "Footnotes",
    "text": "Footnotes\n\nVIF: variance inflation factor; Can be interpreted as how much influence the variable has on the modelâ†©ï¸"
  },
  {
    "objectID": "posts/github-website/index.html",
    "href": "posts/github-website/index.html",
    "title": "Making a Website with GitHub/Quarto",
    "section": "",
    "text": "There are many instructions for making Quarto websites or hosting on GitHub, but here is a list of instructions with links to other more detailed references as a roadmap to get started.\nThis isnâ€™t comprehensive, but hopefully shares enough resources to get you started while clarifying some of the more confusing steps.\nIt can be a bit weird starting out and remember that you may be learning Quarto, git and GitHub (and possibly YAML, CSS and/or SCSS) all at once which is a lot!\nSo if you find it tricky, thatâ€™s normal, itâ€™s nothing you canâ€™t handle :)"
  },
  {
    "objectID": "posts/github-website/index.html#websites-in-general",
    "href": "posts/github-website/index.html#websites-in-general",
    "title": "Making a Website with GitHub/Quarto",
    "section": "Websites in General",
    "text": "Websites in General\nIt helps to have a brief overview of what it takes to get a website on the Internet. Generally there are three steps\n\n1. Create the files\nThis step is where you create (by hand or with software), the actual html files which are the website. You can create these files and not put them on the Internet. Which means you have a website on your computer (local), which only you can see. This is great for previewing your website before putting it, or any changes, onto the Internet.\n\n\n2. Serve the files\nThis is when you put (serve or host) your html files on the Internet. You need a server to serve or host the files and generally you go through an external company1 to do this for you (i.e.Â a Hosting service, or GitHub).\n\n\n3. Link a domain name\nThis step is often optional, depending how you are serving your website. If you use GitHub to serve your website, you will have a website address of https://yourgithubusername.github.io. If you want to buy (or really, rent) a domain name and point it to the website, then you can have a website address of something like https://your-domain-name.com (mine is https://steffilazerte.ca).\n\n\nQuarto and GitHub\nSo if you want to make a website with Quarto and GitHub you will be creating the website files with Quarto (step 1) and serving the files with GitHub (step 2). You can optionally also decide to buy a domain name and link it to your website (step 3)."
  },
  {
    "objectID": "posts/github-website/index.html#step-1.-creating-your-website-with-quarto",
    "href": "posts/github-website/index.html#step-1.-creating-your-website-with-quarto",
    "title": "Making a Website with GitHub/Quarto",
    "section": "Step 1. Creating your Website with Quarto",
    "text": "Step 1. Creating your Website with Quarto\n\nQuarto vs.Â RMarkdown\nYou can create a website with RMarkdown or Quarto.\nQuarto is essentially rMarkdown v2. If you love RMarkdown and donâ€™t want to switch, use that, otherwise itâ€™s worth using Quarto as it has many features not available in RMarkdown.\n\n\nBasic Steps\n\nTo get started, follow the basic steps for Quarto Websites\nCheck out the various Website themes you can use\nMake sure youâ€™re working in a folder (project or repository) called yourgithubusername.github.io\n\n\n\nFiddly bits\nThere are several different ways of hosting your site on GitHub, but the most straightforward way is to â€˜renderâ€™ your site into a docs folder and then tell GitHub to serve that folder (next step).\nBy default your website is created in the _site folder, but you can change this by changing the output-dir option in the _quarto.yml (this is the file that defines your site options).\nFor example, I use output-dir: docs which tells R to create the website in a docs folder.\nTo preview your website, use quarto preview in the terminal (the website will automatically update with any future changes), or render your website and then open the index.html file inside the docs folder (you will need to re-render and refresh the page to see new changes)."
  },
  {
    "objectID": "posts/github-website/index.html#step-2.-serving-your-website-with-github",
    "href": "posts/github-website/index.html#step-2.-serving-your-website-with-github",
    "title": "Making a Website with GitHub/Quarto",
    "section": "Step 2. Serving your Website with GitHub",
    "text": "Step 2. Serving your Website with GitHub\nOnce you have and like your website, youâ€™ll need to push it to GitHub and then tell GitHub that it should serve your website (it wonâ€™t unless you tell it to).\n\nPush your website2 to GitHub. For learning how to push/pull to GitHub, I recommend\n\nHappy Git with R\nBirds Canadaâ€™s â€œGitHub: A Beginnerâ€™s Guideâ€\n\nOnce itâ€™s on GitHub, you can tell GitHub to â€˜serveâ€™ your docs folder, I recommend\n\nQuartoâ€™s instructions for Render to docs\nGitHub Pages Documentation"
  },
  {
    "objectID": "posts/github-website/index.html#link-a-domain-name-optional",
    "href": "posts/github-website/index.html#link-a-domain-name-optional",
    "title": "Making a Website with GitHub/Quarto",
    "section": "3. Link a Domain Name (optional)",
    "text": "3. Link a Domain Name (optional)\nNow youâ€™ll have a lovely website hosted at https://yourusername.github.io. There is nothing wrong with leaving it at this stage, if nothing else, youâ€™re making it really clear that you are badass enough to be able to create a website and serve it on GitHub.\nHowever, if you would like to use your own domain name, you can also do that.\nFirst you will need to buy (rent) a domain name.\nI buy mine (steffilazerte.ca) from Webnames, a Canadian Domain Registrar, but there are many others. If you have one bundled with a webhosting service, you can always transfer it to another Domain Registrar if that works better for you.\nNext, you will need to configure GitHub to work with this domain.\n\nSimplest3 is to follow GitHubâ€™s instructions for Configuring an apex domain\n\nIn short, you will tell GitHub about your Domain and then tell your Domain Registrar to point to GitHub."
  },
  {
    "objectID": "posts/github-website/index.html#examples",
    "href": "posts/github-website/index.html#examples",
    "title": "Making a Website with GitHub/Quarto",
    "section": "Examples",
    "text": "Examples\nHere are examples of several websites Iâ€™ve made and host on GitHub. In particular, take a look at the _quarto.yml files as this is how the pages, navigation and themes are set.\n\nSteffiâ€™s website\n\nServed from the docs folder\nCode: https://github.com/steffilazerte/steffilazerte.github.io\nSite: https://steffilazerte.ca\n\nWestman Naturalistsâ€™ website\n\nQuarto, no docs folder, uses GitHub Actions to publish\nCode: https://github.com/westman-naturalists/westman-naturalists.github.io\nSite: https://westman-naturalists.github.io\nInteresting bits: This site uses a GitHub action to update the Events page everyday at midnight from a Google Spreadsheet."
  },
  {
    "objectID": "posts/github-website/index.html#other-details",
    "href": "posts/github-website/index.html#other-details",
    "title": "Making a Website with GitHub/Quarto",
    "section": "Other details",
    "text": "Other details\n\nBibBase\nBecause I hate updating things by hand which can be automated, I use BibBase to automatically list my Publications and Presentations in my CV by pulling them in from Zotero.\n\n\nUsing R to automate things\nAgain because I hate updating things by hand, I use R code to automate many lists on my webiste.\n\nI use code to create lists of presentation resources with links to the slides. I donâ€™t love this setup and would like to fiddle it in future to be a) more attractive and b) simpler to work with.\nI use code to create the tables displayed in my CV (note that the actual data and some of the functions arenâ€™t included in this repository)"
  },
  {
    "objectID": "posts/github-website/index.html#resources",
    "href": "posts/github-website/index.html#resources",
    "title": "Making a Website with GitHub/Quarto",
    "section": "Resources",
    "text": "Resources\n\nQuarto documentation\n\nQuarto Websites\nHTML Themes in Quarto\nPublishing Quarto Websites with GitHub Pages\n\nGitHub Pages documentation\n\nCreating a GitHub Pages site\nCustom Domains\n\nWorking with git and GitHub\n\nHappy Git with R\nBirds Canadaâ€™s â€œGitHub: A Beginnerâ€™s Guideâ€"
  },
  {
    "objectID": "posts/github-website/index.html#footnotes",
    "href": "posts/github-website/index.html#footnotes",
    "title": "Making a Website with GitHub/Quarto",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nYou can have your computer do this for you, but then your computer needs be on and running (and serving) files 24/7 and requires a more complex setup.â†©ï¸\nYou have to push the docs folder, but generally I recommend pushing all files except anything sensitive you need to keep private. This way you can share the love of how to create your own Quarto Website on GitHub!â†©ï¸\nIn the sense that there are other, more complex things you can do, not in the sense that this is particularly straightforward.â†©ï¸"
  },
  {
    "objectID": "posts/useful-packages/index.html",
    "href": "posts/useful-packages/index.html",
    "title": "Useful R Packages & Resources",
    "section": "",
    "text": "A list of cool R packages & resources, updated when I think about it"
  },
  {
    "objectID": "posts/useful-packages/index.html#stats",
    "href": "posts/useful-packages/index.html#stats",
    "title": "Useful R Packages & Resources",
    "section": "Stats",
    "text": "Stats\nPackages useful for statistical analyses\n\nDHARMa - Model diagnostics\nglmmTMB - Generalized linear mixed models and extensions"
  },
  {
    "objectID": "posts/useful-packages/index.html#visualizations",
    "href": "posts/useful-packages/index.html#visualizations",
    "title": "Useful R Packages & Resources",
    "section": "Visualizations",
    "text": "Visualizations\nPackages useful for visualizing data\n\npatchwork - Joining figures together"
  },
  {
    "objectID": "posts/useful-packages/index.html#acquiring-data",
    "href": "posts/useful-packages/index.html#acquiring-data",
    "title": "Useful R Packages & Resources",
    "section": "Acquiring Data",
    "text": "Acquiring Data\nFor accessing data\n\nweathercan - Download historical ECCC (Canadian) data (my package!)"
  },
  {
    "objectID": "posts/useful-packages/index.html#working-with-data",
    "href": "posts/useful-packages/index.html#working-with-data",
    "title": "Useful R Packages & Resources",
    "section": "Working with Data",
    "text": "Working with Data\nFor working with data or specific data types\n\nPackages\n\ntidyverse - General collection of packages for managing, summarizing, transforming data\nlubridate - Dealing with dates and datetimes\nstringr - Pattern match strings (text)\n\nAmazing article on how to use regex\n\nassertr - Test that your data is as it should be\n\n\n\nResources\n\nR for Data Science [book] by Hadley Wickham, Mine Ã‡etinkaya-Rundel, and Garrett Grolemund\nR4DS Online Learning Community - Community for learning R, generally with the tidyverse, originally developed as an â€œR for Data Scienceâ€ (R4DS) book club"
  },
  {
    "objectID": "posts/useful-packages/index.html#spatial-data",
    "href": "posts/useful-packages/index.html#spatial-data",
    "title": "Useful R Packages & Resources",
    "section": "Spatial Data",
    "text": "Spatial Data\n\nPackages\n\nsf - GIS work with spatial data\nggspatial - Adding more options for plotting spatial data in ggplot2\nmapview - Quick interactive maps\nrnaturalearth - Get spatial map files from NaturalEarth\n\n\n\nResources\n\nSpatial Data Science [book] by Edzer Pebesma and Roger Bivand"
  },
  {
    "objectID": "posts/useful-packages/index.html#workflows",
    "href": "posts/useful-packages/index.html#workflows",
    "title": "Useful R Packages & Resources",
    "section": "Workflows",
    "text": "Workflows\nPackages useful for workflows\n\npak - For installing packages from any locations\n\nI find pak more informative, quicker, and just simpler than install.packages()\ne.g., pak::pkg_install(\"packageName\")\n\nquarto - A package but also a standalone program for creating reports from your R scripts\ngt - Creates pretty tables for reports"
  },
  {
    "objectID": "posts/useful-packages/index.html#package-development1",
    "href": "posts/useful-packages/index.html#package-development1",
    "title": "Useful R Packages & Resources",
    "section": "Package Development1",
    "text": "Package Development1\n\nPackages\n\nusethis - Automates a lot of setup to make things quicker\n\ne.g., usethis::use_testthat() to quickly set up testthat infrastructure\n\npkgdown - Create package documentation website from your docs and vignettes\ntestthat - Tests for your package\n\n\n\nResources\n\nR packages [book] by Hadley Wickham and Jennifer Bryan"
  },
  {
    "objectID": "posts/useful-packages/index.html#footnotes",
    "href": "posts/useful-packages/index.html#footnotes",
    "title": "Useful R Packages & Resources",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nMaking packagesâ†©ï¸"
  },
  {
    "objectID": "posts/workflow/index.html",
    "href": "posts/workflow/index.html",
    "title": "Statistical Workflow",
    "section": "",
    "text": "A statistical workflow is generally the same for most analyses, and thinking your way through this workflow can help you decide what kind of analysis youâ€™d like to do.\n\nDecide on your question(s)\n\nHelps guide exploration and models\n\nPreliminary data exploration\n\nHelps determine answers to questions and guide model development\n\nDecide on a model type\n\nSimple linear model, generalized linear model, mixed model, etc.\nWhat package to use for this model\n\nRun model\nCheck model diagnostics/assumptions\n\nAs required, go back to Step 3 (Model type)\n\nConsider transformations if required\n\nIf so, go back to Step 4 (Run Model)\n\nInterpret model\n\nSummary tables\nANOVA tables\nPost-Hoc analyses\n\nCreate figures to visually show your model results"
  },
  {
    "objectID": "teaching.html",
    "href": "teaching.html",
    "title": "Teaching and Outreach",
    "section": "",
    "text": "I find teaching and sharing my research with others immensely gratifying. In the past I have hosted R Coffee Hours and the corresponding ThinkR website as a way of helping students working with R statistical software. Further, as most research is publicly funded, to some degree I consider outreach and education a social responsibility. I enjoy having discussions about research and sharing or inspiring exciting and interesting ideas. I also enjoy hearing about new and interesting ideas or concerns about research. I have, therefore, deliberately sought opportunities to both improve my teaching skills and share the results of my research with interested parties.\nFor a list of teaching related activities see the Teaching section of my CV.\nFor a list of outreach related activities see the Outreach section of my CV."
  }
]